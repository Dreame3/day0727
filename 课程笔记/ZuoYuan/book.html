<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.9">
<meta name="author" content="Yuan Zuo">
<title>尚硅谷Flink教程</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt,.quoteblock .quoteblock{margin:0 0 1.25em;padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>尚硅谷Flink教程</h1>
<div class="details">
<span id="author" class="author">Yuan Zuo</span><br>
<span id="email" class="email"><a href="mailto:zuoyuan@atguigu.com">zuoyuan@atguigu.com</a></span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_第一章_flink简介">第一章 Flink简介</a>
<ul class="sectlevel2">
<li><a href="#_1_初识flink">1. 初识Flink</a></li>
<li><a href="#_2_flink的重要特点">2. Flink的重要特点</a></li>
</ul>
</li>
<li><a href="#_第二章_flink快速上手">第二章 Flink快速上手</a>
<ul class="sectlevel2">
<li><a href="#_1_使用maven搭建工程">1. 使用Maven搭建工程</a></li>
<li><a href="#_2_flink部署">2. Flink部署</a></li>
</ul>
</li>
<li><a href="#_第三章_flink运行架构">第三章 Flink运行架构</a>
<ul class="sectlevel2">
<li><a href="#_3_1_任务调度原理">3.1 任务调度原理</a></li>
<li><a href="#_3_2_worker与slots">3.2 Worker与Slots</a></li>
<li><a href="#_3_3_程序与数据流">3.3 程序与数据流</a></li>
<li><a href="#_3_4_并行数据流">3.4 并行数据流</a></li>
<li><a href="#_3_5_task与operator_chains">3.5 task与operator chains</a></li>
</ul>
</li>
<li><a href="#_第四章_flink_流处理api">第四章 Flink 流处理Api</a>
<ul class="sectlevel2">
<li><a href="#_4_1_environment">4.1 Environment</a></li>
<li><a href="#_4_2_source">4.2 Source</a></li>
<li><a href="#_4_3_transform">4.3 Transform</a></li>
<li><a href="#_4_4_sink">4.4 Sink</a></li>
</ul>
</li>
<li><a href="#_第五章_time与window">第五章 Time与Window</a>
<ul class="sectlevel2">
<li><a href="#_5_1_time">5.1 Time</a></li>
<li><a href="#_5_2_window">5.2 Window</a></li>
<li><a href="#_5_3_window_api">5.3 Window API</a></li>
</ul>
</li>
<li><a href="#_第六章_eventtime与window">第六章 EventTime与Window</a>
<ul class="sectlevel2">
<li><a href="#_6_1_eventtime的引入">6.1 EventTime的引入</a></li>
<li><a href="#_6_2_watermark">6.2 Watermark</a></li>
<li><a href="#_6_3_evnettimewindow_api">6.3 EvnetTimeWindow API</a></li>
</ul>
</li>
<li><a href="#_第七章_table_api_与sql">第七章 Table API 与SQL</a>
<ul class="sectlevel2">
<li><a href="#_7_1_需要引入的pom依赖">7.1 需要引入的pom依赖</a></li>
<li><a href="#_7_2_构造表环境">7.2 构造表环境</a></li>
<li><a href="#_7_3_通过一个例子_了解tableapi">7.3 通过一个例子 了解TableAPI</a></li>
<li><a href="#_7_4_sql如何编写">7.4 SQL如何编写</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_第一章_flink简介">第一章 Flink简介</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_初识flink">1. 初识Flink</h3>
<div class="paragraph">
<p>Flink起源于Stratosphere项目，Stratosphere是在2010~2014年由3所地处柏林的大学和欧洲的一些其他的大学共同进行的研究项目，2014年4月Stratosphere的代码被复制并捐赠给了Apache软件基金会，参加这个孵化项目的初始成员是Stratosphere系统的核心开发人员，2014年12月，Flink一跃成为Apache软件基金会的顶级项目。</p>
</div>
<div class="paragraph">
<p>在德语中，Flink一词表示快速和灵巧，项目采用一只松鼠的彩色图案作为logo，这不仅是因为松鼠具有快速和灵巧的特点，还因为柏林的松鼠有一种迷人的红棕色，而Flink的松鼠logo拥有可爱的尾巴，尾巴的颜色与Apache软件基金会的logo颜色相呼应，也就是说，这是一只Apache风格的松鼠。</p>
</div>
<div class="openblock float-group">
<div class="content">
<div class="imageblock left">
<div class="content">
<img src="images/ASF20thAnniversary.jpg" alt="ASF20thAnniversary" width="300" height="200">
</div>
<div class="title">Figure 1. apache logo</div>
</div>
<div class="imageblock left">
<div class="content">
<img src="images/flink-header-logo.svg" alt="flink header logo" width="300" height="200">
</div>
<div class="title">Figure 2. apache flink logo</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Flink主页在其顶部展示了该项目的理念: "<span class="red">Apache Flink是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源流处理框架</span>"。</p>
</div>
<div class="paragraph">
<p>Apache Flink是一个框架和分布式处理引擎，<span class="red">用于对无界和有界数据流进行有状态计算</span>。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/flink-home-graphic.png" alt="flink home graphic">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_flink的重要特点">2. Flink的重要特点</h3>
<div class="sect3">
<h4 id="_2_1_事件驱动型event_driven">2.1 事件驱动型(Event-Driven)</h4>
<div class="paragraph">
<p>事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。比较典型的就是以Kafka为代表的消息队列几乎都是事件驱动型应用。</p>
</div>
<div class="paragraph">
<p>与之不同的就是Spark Streaming微批次，如图：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/streaming-flow.png" alt="streaming flow">
</div>
</div>
<div class="paragraph">
<p>事件驱动型：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/usecases-eventdrivenapps.png" alt="usecases eventdrivenapps">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_2_2_流与批的世界观">2.2 流与批的世界观</h4>
<div class="paragraph">
<p><strong>批处理</strong>的特点是有界、持久、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。</p>
</div>
<div class="paragraph">
<p><strong>流处理</strong>的特点是无界、实时，无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。</p>
</div>
<div class="paragraph">
<p>在Spark的世界观中，一切都是由批次组成的，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。</p>
</div>
<div class="paragraph">
<p>而在Flink的世界观中，一切都是由流组成的，离线数据是有界限的流，实时数据是一个没有界限的流，这就是所谓的有界流和无界流。</p>
</div>
<div class="paragraph">
<p><strong>无界数据流</strong>：无界数据流有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序(例如事件发生的顺序)获取event，以便能够推断结果完整性。</p>
</div>
<div class="paragraph">
<p><strong>有界数据流</strong>：有界数据流有明确定义的开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bounded-unbounded.png" alt="bounded unbounded">
</div>
</div>
<div class="paragraph">
<p><span class="red">这种以流为世界观的架构，获得的最大好处就是具有极低的延迟。</span></p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_分层api">2.3 分层api</h4>
<div class="imageblock">
<div class="content">
<img src="images/api-stack.png" alt="api stack">
</div>
</div>
<div class="paragraph">
<p>最底层级的抽象仅仅提供了有状态流，它将通过在DataStream API中嵌入Process Function来处理数据。Process Function与DataStream API相集成，使其可以对某些特定的操作进行底层的抽象，它允许用户可以自由地处理来自一个或多个数据流的事件，并使用一致的容错的状态。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以处理复杂的计算。</p>
</div>
<div class="paragraph">
<p>实际上，大多数应用并不需要上述的底层抽象，而是针对核心API(Core APIs)进行编程，比如DataStream API(有界或无界流数据)以及DataSet API(有界数据集)。这些API为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换(transformations)，连接(joins)，聚合(aggregations)，窗口操作(window)等等。DataSet API为有界数据集提供了额外的支持，例如循环与迭代。这些API处理的数据类型以类(classes)的形式由各自的编程语言所表示。</p>
</div>
<div class="paragraph">
<p>Table API是以表为中心的声明式编程，其中表可能会动态变化(在表达流数据时)。Table API遵循(扩展的)关系模型：表有二维数据结构(schema)(类似于关系数据库中的表)，同时API提供与RDBMS相似的操作，例如select、project、join、group-by、aggregate等。Table API程序声明式地定义了什么逻辑操作应该执行，而不是准确地确定这些操作代码看上去如何(过程式编程风格)。尽管Table API可以通过多种类型的用户自定义函数(UDF)进行扩展，其仍不如核心API更具表达能力，但是使用起来却更加简洁(代码量更少)。除此之外，Table API程序在执行之前会经过内置优化器进行优化。</p>
</div>
<div class="paragraph">
<p>你可以在表与DataStream/DataSet之间无缝切换，以允许程序将Table API与DataStream以及DataSet混合使用。</p>
</div>
<div class="paragraph">
<p>Flink提供的最高层级的抽象是SQL。这一层抽象在语法与表达能力上与Table API类似，但是是以SQL查询表达式的形式表现程序。SQL抽象与Table API交互密切，同时SQL查询可以直接在Table API定义的表上执行。</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<div class="title">Warning</div>
</td>
<td class="content">
目前Flink作为批处理还不是主流，不如Spark成熟，所以DataSet使用的并不是很多。Flink Table API和Flink SQL也并不完善，大多都由各大厂商自己定制。所以我们主要学习DataStream API的使用。实际上Flink作为最接近Google DataFlow模型的实现，是流批统一的观点，所以基本上使用DataStream就可以了，DataSet并不是很地道。
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第二章_flink快速上手">第二章 Flink快速上手</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_使用maven搭建工程">1. 使用Maven搭建工程</h3>
<div class="paragraph">
<p><strong>IDE推荐Idea</strong></p>
</div>
<div class="sect3">
<h4 id="_1_1_pom_xml文件">1.1 pom.xml文件</h4>
<div class="listingblock">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlight"><code class="language-xml" data-lang="xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.atguigu.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-scala_2.11&lt;/artifactId&gt;
            &lt;version&gt;1.7.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-scala --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
            &lt;artifactId&gt;flink-streaming-scala_2.11&lt;/artifactId&gt;
            &lt;version&gt;1.7.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;!-- 该插件用于将Scala代码编译成class文件 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;
                &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.4.6&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;!-- 声明绑定到maven的compile阶段 --&gt;
                        &lt;goals&gt;

                            &lt;goal&gt;testCompile&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.0.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;descriptorRefs&gt;
                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                    &lt;/descriptorRefs&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;single&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_添加scala文件夹或者将java文件夹rename为scala">1.2 添加scala文件夹或者将java文件夹rename为scala</h4>
<div class="listingblock">
<div class="title">StreamWcApp.scala</div>
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}

object StreamWcApp {

  def main(args: Array[String]): Unit = {
    //创建流处理环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
    //接收socket文本流
    val textDstream: DataStream[String] = env.socketTextStream("localhost", 9000, "\n")

    // flatMap和Map需要引用的隐式转换
    import org.apache.flink.api.scala._
    // 处理, 分组并且sum聚合
    val dStream: DataStream[(String, Int)] = textDstream
        // 使用空白符进行切割，并且遍历每一个单词
        .flatMap(_.split("\\s"))
        // 过滤出非空
        .filter(_.nonEmpty)
        // 这一步实现了mr中的map
        .map((_, 1))
        // 使用第0个元素为key进行聚合
        .keyBy(0)
        // tumbling window: 滚动窗口, [9:00:00, 9:00:05), [9:00:05, 9:00:10)
        .timeWindow(Time.seconds(5))
        // 实现了mr的reduce语义
        .sum(1)

    // 打印
    dStream.print()

    env.execute()
  }
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-shell" data-lang="shell">nc -lk 9999</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_flink部署">2. Flink部署</h3>
<div class="sect3">
<h4 id="_1_下载hadoop_free版本的flink">1. 下载Hadoop Free版本的Flink</h4>
<div class="paragraph">
<p><a href="https://www.apache.org/dyn/closer.lua/flink/flink-1.7.2/flink-1.7.2-bin-scala_2.11.tgz">下载链接</a></p>
</div>
</div>
<div class="sect3">
<h4 id="_2_解压缩">2. 解压缩</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-shell" data-lang="shell">$ tar xvfz flink-1.7.2-bin-scala_2.11.tgz</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_启动flink集群">3. 启动Flink集群</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-shell" data-lang="shell">$ cd flink-1.7.2
$ ./bin/start-cluster.sh</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_在浏览器中打开flink的web_ui">4. 在浏览器中打开Flink的Web UI</h4>
<div class="paragraph">
<p><a href="http://localhost:8081" class="bare">http://localhost:8081</a></p>
</div>
</div>
<div class="sect3">
<h4 id="_5_编译我们编写好的wordcount程序">5. 编译我们编写好的wordcount程序</h4>
<div class="paragraph">
<p>在Idea中使用maven package功能打包。</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_提交打包好的程序">6. 提交打包好的程序</h4>
<div class="paragraph">
<p>$ ./bin/flink run -c xxxx.jar</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_在flink_web_ui查看dashboard中job的执行状态">7. 在Flink Web UI查看Dashboard中job的执行状态</h4>

</div>
<div class="sect3">
<h4 id="_8_停止flink集群">8. 停止Flink集群</h4>
<div class="paragraph">
<p>$ ./bin/stop-cluster.sh</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第三章_flink运行架构">第三章 Flink运行架构</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_3_1_任务调度原理">3.1 任务调度原理</h3>
<div class="imageblock">
<div class="content">
<img src="images/processes.svg" alt="processes">
</div>
</div>
<div class="paragraph">
<p>客户端不是运行时和程序执行的一部分，但它用于准备并发送Dataflow(JobGraph)给Master(JobManager)，然后，客户端断开连接或者维持连接以等待接收计算结果。</p>
</div>
<div class="paragraph">
<p>当Flink集群启动后，首先会启动一个JobManger和一个或多个的TaskManager。由Client提交任务给JobManager，JobManager再调度任务到各个TaskManager去执行，然后TaskManager将心跳和统计信息汇报给JobManager。TaskManager之间以流的形式进行数据的传输。上述三者均为独立的JVM进程。</p>
</div>
<div class="paragraph">
<p>Client为提交Job的客户端，可以运行在任何机器上(与JobManager环境连通即可)。提交Job后，Client可以结束进程(Streaming的任务)，也可以不结束并等待结果返回。</p>
</div>
<div class="paragraph">
<p>JobManager主要负责调度Job并协调Task做checkpoint。从Client处接收到Job和JAR包等资源后，会生成优化后的执行计划，并以Task为单元调度到各个TaskManager去执行。</p>
</div>
<div class="paragraph">
<p>TaskManager在启动的时候就设置好了槽位数(Slot)，每个Slot能启动一个Task，Task为线程。从JobManager处接收需要部署的Task，部署启动后，与自己的上游建立Netty连接，接收数据并处理。</p>
</div>
<div class="paragraph">
<p><strong>关于执行图</strong></p>
</div>
<div class="paragraph">
<p>Flink中的执行图可以分成四层：StreamGraph &#8594; JobGraph &#8594; ExecutionGraph &#8594; 物理执行图。</p>
</div>
<div class="paragraph">
<p><strong>StreamGraph</strong>：是根据用户通过Stream API编写的代码生成的最初的图。用来表示程序的拓扑结构。</p>
</div>
<div class="paragraph">
<p><strong>JobGraph</strong>：StreamGraph经过优化后生成了JobGraph，提交给JobManager的数据结构。主要的优化为，将多个符合条件的节点chain在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。</p>
</div>
<div class="paragraph">
<p><strong>ExecutionGraph</strong>：JobManager根据JobGraph生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。</p>
</div>
<div class="paragraph">
<p><strong>物理执行图</strong>：JobManager根据ExecutionGraph对Job进行调度后，在各个TaskManager上部署Task后形成的"图"，并不是一个具体的数据结构。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/jobgraph.png" alt="jobgraph">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_3_2_worker与slots">3.2 Worker与Slots</h3>
<div class="paragraph">
<p>每一个worker(TaskManager)是一个JVM进程，它可能会在独立的线程上执行一个或多个subtask。为了控制一个worker能接收多少个task，worker通过task slot来进行控制(一个worker至少有一个task slot)。</p>
</div>
<div class="paragraph">
<p>每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个subtask将不需要跟来自其他job的subtask竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。</p>
</div>
<div class="paragraph">
<p>通过调整task slot的数量，允许用户定义subtask之间如何互相隔离。如果一个TaskManager一个slot，那将意味着每个task group运行在独立的JVM中(该JVM可能是通过一个特定的容器启动的)，而一个TaskManager多个slot意味着更多的subtask可以共享同一个JVM。而在同一个JVM进程中的task将共享TCP连接(基于IO多路复用)和心跳消息。它们也可能共享数据集和数据结构，因此这减少了每个task的负载。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/tasks_slots.svg" alt="tasks slots">
</div>
</div>
<div class="paragraph">
<p>Task Slot是静态的概念，是指TaskManager具有的并发执行能力，可以通过参数taskmanager.numberOfTaskSlots进行配置，而并行度parallelism是动态概念，即TaskManager运行程序时实际使用的并发能力，可以通过参数parallelism.default进行配置。</p>
</div>
<div class="paragraph">
<p>也就是说，假设一共有3个TaskManager，每一个TaskManager中的分配3个Task Slot，也就是每个TaskManager可以接收3个task，一共9个Task Slot，如果我们设置parallelism.default=1，即运行程序默认的并行度为1，9个TaskSlot只用了1个，有8个空闲，因此，设置合适的并行度才能提高效率。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/slots_parallelism.svg" alt="slots parallelism">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_3_3_程序与数据流">3.3 程序与数据流</h3>
<div class="imageblock">
<div class="content">
<img src="images/program_dataflow.svg" alt="program dataflow">
</div>
</div>
<div class="paragraph">
<p>所有的Flink程序都是由三部分组成的：Source、Transformation和Sink。</p>
</div>
<div class="paragraph">
<p>Source负责读取数据源，Transformation利用各种算子进行处理加工，Sink负责输出。</p>
</div>
<div class="paragraph">
<p>在运行时，Flink上运行的程序会被映射成Streaming Dataflows，它包含了这三部分。每一个Dataflow以一个或多个sources开始以一个或多个sinks结束。dataflow类似于任意的有向无环图(DAG)，当然特定形式的环可以通过iteration构建。在大部分情况下，程序中的transformations跟dataflow中的operator是一一对应的关系，但有时候，一个transformation可能对应多个operator。</p>
</div>
</div>
<div class="sect2">
<h3 id="_3_4_并行数据流">3.4 并行数据流</h3>
<div class="paragraph">
<p>Flink程序的执行具有并行、分布式的特性。在执行过程中，一个 stream 包含一个或多个 stream partition ，而每一个 operator 包含一个或多个 operator subtask，这些operator subtasks在不同的线程、不同的物理机或不同的容器中彼此互不依赖得执行。
一个特定operator的subtask的个数被称之为其parallelism(并行度)。一个stream的并行度总是等同于其producing operator的并行度。一个程序中，不同的operator可能具有不同的并行度。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/parallel_dataflow.svg" alt="parallel dataflow">
</div>
</div>
<div class="paragraph">
<p>Stream在operator之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式，具体是哪一种形式，取决于operator的种类。
One-to-one：stream(比如在source和map operator之间)维护着分区以及元素的顺序。那意味着map operator的subtask看到的元素的个数以及顺序跟source operator的subtask生产的元素的个数、顺序相同，map、fliter、flatMap等算子都是one-to-one的对应关系。
类似于spark中的窄依赖
Redistributing：stream(map()跟keyBy/window之间或者keyBy/window跟sink之间)的分区会发生改变。每一个operator subtask依据所选择的transformation发送数据到不同的目标subtask。例如，keyBy() 基于hashCode重分区、broadcast和rebalance会随机重新分区，这些算子都会引起redistribute过程，而redistribute过程就类似于Spark中的shuffle过程。
类似于spark中的宽依赖</p>
</div>
</div>
<div class="sect2">
<h3 id="_3_5_task与operator_chains">3.5 task与operator chains</h3>
<div class="paragraph">
<p>相同并行度的one to one操作，Flink这样相连的operator链接在一起形成一个task，原来的operator成为里面的subtask。将operators链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/operatorschains.png" alt="operatorschains">
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第四章_flink_流处理api">第四章 Flink 流处理Api</h2>
<div class="sectionbody">
<div class="paragraph">
<p>environment &#8594; source &#8594; transform &#8594; sink</p>
</div>
<div class="sect2">
<h3 id="_4_1_environment">4.1 Environment</h3>
<div class="paragraph">
<p>getExecutionEnvironment</p>
</div>
<div class="paragraph">
<p>创建一个执行环境，表示当前执行程序的上下文。如果程序是独立调用的，则此方法返回本地执行环境；如果从命令行客户端调用程序以提交到集群，则此方法返回此集群的执行环境，也就是说，getExecutionEnvironment会根据查询运行的方式决定返回什么样的运行环境，是最常用的一种创建执行环境的方式。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果没有设置并行度，会以flink-conf.yaml中的配置为准，默认是1</p>
</div>
<div class="paragraph">
<p>createLocalEnvironment
返回本地执行环境，需要在调用时指定默认的并行度。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">val env = StreamExecutionEnvironment.createLocalEnvironment(1)</code></pre>
</div>
</div>
<div class="paragraph">
<p>createRemoteEnvironment
返回集群执行环境，将Jar提交到远程服务器。需要在调用时指定JobManager的IP和端口号，并指定要在集群中运行的Jar包。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">val env = ExecutionEnvironment.createRemoteEnvironment("node", 6123,"C://jar//flink//wordcount.jar")</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_2_source">4.2 Source</h3>
<div class="paragraph">
<p>创建Kafka工具类</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">object MyKafkaUtil {

  val prop = new Properties()

  prop.setProperty("bootstrap.servers","hadoop1:9092")
  prop.setProperty("group.id","gmall")

  def getConsumer(topic:String ):FlinkKafkaConsumer011[String]= {
      val myKafkaConsumer:FlinkKafkaConsumer011[String] = new FlinkKafkaConsumer011[String](topic, new SimpleStringSchema(), prop)
     myKafkaConsumer
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>增加业务主类StartupApp</p>
</div>
<div class="listingblock">
<div class="content">
<pre>object StartupApp {
    def main(args: Array[String]): Unit = {
        val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

        val kafkaConsumer  =MyKafkaUtil.getConsumer("GMALL_STARTUP")

        val dstream: DataStream[String] = environment.addSource(kafkaConsumer)

        dstream.print()

        environment.execute()
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Flink+Kafka是如何实现exactly-once语义的</p>
</div>
<div class="paragraph">
<p>Flink通过checkpoint来保存数据是否处理完成的状态</p>
</div>
<div class="paragraph">
<p>由JobManager协调各个TaskManager进行checkpoint存储，checkpoint保存在 StateBackend中，默认StateBackend是内存级的，也可以改为文件级的进行持久化保存。</p>
</div>
<div class="paragraph">
<p>执行过程实际上是一个两段式提交，每个算子执行完成，会进行“预提交”，直到执行完sink操作，会发起“确认提交”，如果执行失败，预提交会放弃掉。
如果宕机需要通过StateBackend进行恢复，只能恢复所有确认提交的操作。</p>
</div>
<div class="paragraph">
<p><a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html" class="bare">https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html</a></p>
</div>
<div class="paragraph">
<p>文档</p>
</div>
</div>
<div class="sect2">
<h3 id="_4_3_transform">4.3 Transform</h3>
<div class="paragraph">
<p>转换算子</p>
</div>
<div class="sect3">
<h4 id="_4_3_1_map">4.3.1 map</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">val streamMap = stream.map { x =&gt; x * 2 }</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_2_flatmap">4.3.2 flatMap</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">val streamFlatMap = stream.flatMap{
  x =&gt; x.split(" ")
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_3_filter">4.3.3 Filter</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">val streamFilter = stream.filter{
  x =&gt; x == 1
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_4_keyby">4.3.4 KeyBy</h4>
<div class="paragraph">
<p>DataStream → KeyedStream：输入必须是Tuple类型，逻辑地将一个流拆分成不相交的分区，每个分区包含具有相同key的元素，在内部以hash的形式实现的。</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_5_reduce">4.3.5 Reduce</h4>
<div class="paragraph">
<p>KeyedStream → DataStream：一个分组数据流的聚合操作，合并当前的元素和上次聚合的结果，产生一个新的值，返回的流中包含每一次聚合的结果，而不是只返回最后一次聚合的最终结果。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">//求各个渠道的累计个数
val startUplogDstream: DataStream[StartUpLog] = dstream.map{ JSON.parseObject(_,classOf[StartUpLog])}
val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//reduce //sum
keyedStream.reduce{  (ch1,ch2)=&gt;
  (ch1._1,ch1._2+ch2._2)
} .print().setParallelism(1)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_6_split_和_select">4.3.6 Split 和 Select</h4>
<div class="paragraph">
<p>Split</p>
</div>
<div class="paragraph">
<p>DataStream → SplitStream：根据某些特征把一个DataStream拆分成两个或者多个DataStream。
Select</p>
</div>
<div class="paragraph">
<p>SplitStream→DataStream：从一个SplitStream中获取一个或者多个DataStream。</p>
</div>
<div class="paragraph">
<p>需求：把appstore和其他的渠道的数据单独拆分出来，做成两个流</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">     // 将appstore与其他渠道拆分拆分出来  成为两个独立的流
val splitStream: SplitStream[StartUpLog] = startUplogDstream.split { startUplog =&gt;
  var flags:List[String] =  null
  if ("appstore" == startUplog.ch) {
    flags = List(startUplog.ch)
  } else {
    flags = List("other" )
  }
  flags
}
val appStoreStream: DataStream[StartUpLog] = splitStream.select("appstore")
appStoreStream.print("apple:").setParallelism(1)
val otherStream: DataStream[StartUpLog] = splitStream.select("other")
otherStream.print("other:").setParallelism(1)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_7_connect和comap">4.3.7 Connect和CoMap</h4>
<div class="paragraph">
<p>DataStream,DataStream → ConnectedStreams：连接两个保持他们类型的数据流，两个数据流被Connect之后，只是被放在了一个同一个流中，内部依然保持各自的数据和形式不发生任何变化，两个流相互独立。
CoMap,CoFlatMap</p>
</div>
<div class="paragraph">
<p>ConnectedStreams → DataStream：作用于ConnectedStreams上，功能与map和flatMap一样，对ConnectedStreams中的每一个Stream分别进行map和flatMap处理。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">//合并以后打印
val connStream: ConnectedStreams[StartUpLog, StartUpLog] = appStoreStream.connect(otherStream)
val allStream: DataStream[String] = connStream.map(
  (log1: StartUpLog) =&gt; log1.ch,
  (log2: StartUpLog) =&gt; log2.ch
)
allStream.print("connect::")</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_8_union">4.3.8 Union</h4>
<div class="paragraph">
<p>DataStream → DataStream：对两个或者两个以上的DataStream进行union操作，产生一个包含所有DataStream元素的新DataStream。注意:如果你将一个DataStream跟它自己做union操作，在新的DataStream中，你将看到每一个元素都出现两次。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">//合并以后打印
val unionStream: DataStream[StartUpLog] = appStoreStream.union(otherStream)
unionStream.print("union:::")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Connect与 Union 区别：
1 、 Union之前两个流的类型必须是一样，Connect可以不一样，在之后的coMap中再去调整成为一样的。
2 Connect只能操作两个流，Union可以操作多个</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_4_sink">4.4 Sink</h3>
<div class="literalblock">
<div class="content">
<pre>Flink没有类似于spark中foreach方法，让用户进行迭代的操作。虽有对外的输出操作都要利用Sink完成。最后通过类似如下方式完成整个任务最终输出操作。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>myDstream.addSink(new MySink(xxxx))</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>官方提供了一部分的框架的sink。除此以外，需要用户自定义实现sink。</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka-0.11 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>mykafkaUtil中增加方法</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def getProducer(topic:String): FlinkKafkaProducer011[String] ={
  new FlinkKafkaProducer011[String](brokerList,topic,new SimpleStringSchema())
}</pre>
</div>
</div>
<div class="paragraph">
<p>主函数中添加sink</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val myKafkaProducer: FlinkKafkaProducer011[String] = MyKafkaUtil.getProducer("channel_sum")

sumDstream.map( chCount=&gt;chCount._1+":"+chCount._2 ).addSink(myKafkaProducer)</pre>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_1_elasticsearch">4.4.1 Elasticsearch</h4>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-connector-elasticsearch6_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
    &lt;version&gt;4.5.3&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>添加MyEsUtil</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import java.util

import com.alibaba.fastjson.{JSON, JSONObject}
import org.apache.flink.api.common.functions.RuntimeContext
import org.apache.flink.streaming.connectors.elasticsearch.{ElasticsearchSinkFunction, RequestIndexer}
import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink
import org.apache.http.HttpHost
import org.elasticsearch.action.index.IndexRequest
import org.elasticsearch.client.Requests

object MyEsUtil {

  val httpHosts = new util.ArrayList[HttpHost]
  httpHosts.add(new HttpHost("hadoop1",9200,"http"))
   httpHosts.add(new HttpHost("hadoop2",9200,"http"))
   httpHosts.add(new HttpHost("hadoop3",9200,"http"))

  def  getElasticSearchSink(indexName:String):  ElasticsearchSink[String]  ={
    val esFunc = new ElasticsearchSinkFunction[String] {
      override def process(element: String, ctx: RuntimeContext, indexer: RequestIndexer): Unit = {
        println("试图保存："+element)
        val jsonObj: JSONObject = JSON.parseObject(element)
        val indexRequest: IndexRequest = Requests.indexRequest().index(indexName).`type`("_doc").source(jsonObj)
        indexer.add(indexRequest)
        println("保存1条")
      }
    }

    val sinkBuilder = new ElasticsearchSink.Builder[String](httpHosts, esFunc)

    //刷新前缓冲的最大动作量
    sinkBuilder.setBulkFlushMaxActions(10)

    sinkBuilder.build()
  }
}</pre>
</div>
</div>
<div class="paragraph">
<p>在main方法中调用</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-scala" data-lang="scala">// 明细发送到es 中
val esSink: ElasticsearchSink[String] = MyEsUtil.getElasticSearchSink("gmall0503_startup")
dstream.addSink(esSink)</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第五章_time与window">第五章 Time与Window</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_5_1_time">5.1 Time</h3>
<div class="paragraph">
<p>在Flink的流式处理中，会涉及到时间的不同概念，如下图所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/event_ingestion_processing_time.svg" alt="event ingestion processing time">
</div>
</div>
<div class="paragraph">
<p><strong>Event Time</strong>：是事件创建的时间。它通常由事件中的时间戳描述，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件时间戳。
<strong>Ingestion Time</strong>：是数据进入Flink的时间。
<strong>Processing Time</strong>：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Time。
例如，一条日志进入Flink的时间为2017-11-12 10:00:00.123，到达Window的系统时间为2017-11-12 10:00:01.234，日志的内容如下:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2017-11-02 18:37:15.624 INFO Fail over to rm2</pre>
</div>
</div>
<div class="paragraph">
<p>对于业务来说，要统计1min内的故障日志个数，哪个时间是最有意义的？—— eventTime，因为我们要根据日志的生成时间进行统计。</p>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_window">5.2 Window</h3>
<div class="sect3">
<h4 id="_5_2_1_window概述">5.2.1 Window概述</h4>
<div class="paragraph">
<p>streaming流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，而window是一种切割无限数据为有限块进行处理的手段。
Window是无限数据流处理的核心，Window将一个无限的stream拆分成有限大小的”buckets”桶，我们可以在这些桶上做计算操作。
==== 5.2.2 Window类型
Window可以分成两类：
CountWindow：按照指定的数据条数生成一个Window，与时间无关。
TimeWindow：按照时间生成Window。
对于TimeWindow，可以根据窗口实现原理的不同分成三类：滚动窗口（Tumbling Window）、滑动窗口（Sliding Window）和会话窗口（Session Window）。
滚动窗口（Tumbling Windows）
将数据依据固定的窗口长度对数据进行切片。
特点：时间对齐，窗口长度固定，没有重叠。
滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，并且不会出现重叠。例如：如果你指定了一个5分钟大小的滚动窗口，窗口的创建如下图所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/tumbling-windows.svg" alt="tumbling windows">
</div>
</div>
<div class="paragraph">
<p>适用场景：适合做BI统计等（做每个时间段的聚合计算）。
滑动窗口（Sliding Windows）
滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成。
特点：时间对齐，窗口长度固定，有重叠。
滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，窗口是可以重叠的，在这种情况下元素会被分配到多个窗口中。
例如，你有10分钟的窗口和5分钟的滑动，那么每个窗口中5分钟的窗口里包含着上个10分钟产生的数据，如下图所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/sliding-windows.svg" alt="sliding windows">
</div>
</div>
<div class="paragraph">
<p>适用场景：对最近一个时间段内的统计（求某接口最近5min的失败率来决定是否要报警）。
会话窗口（Session Windows）
由一系列事件组合一个指定时间长度的timeout间隙组成，类似于web应用的session，也就是一段时间没有接收到新数据就会生成新的窗口。
特点：时间无对齐。
session窗口分配器通过session活动来对元素进行分组，session窗口跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况，相反，当它在一个固定的时间周期内不再收到元素，即非活动间隔产生，那个这个窗口就会关闭。一个session窗口通过一个session间隔来配置，这个session间隔定义了非活跃周期的长度，当这个非活跃周期产生，那么当前的session将关闭并且后续的元素将被分配到新的session窗口中去。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/session-windows.svg" alt="session windows">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_3_window_api">5.3 Window API</h3>
<div class="paragraph">
<p>TimeWindow
TimeWindow是将指定时间范围内的所有数据组成一个window，一次对一个window里面的所有数据进行计算。
滚动窗口
Flink默认的时间窗口根据Processing Time 进行窗口的划分，将Flink获取到的数据根据进入Flink的时间划分到不同的窗口中。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//每10统计一次各个渠道的计数
val windowedStream: WindowedStream[(String, Int), Tuple, TimeWindow] = keyedStream.timeWindow(Time.seconds(10))
val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
<div class="paragraph">
<p>时间间隔可以通过Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。
滑动窗口（SlidingEventTimeWindows）
滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。
下面代码中的sliding_size设置为了2s，也就是说，窗口每2s就计算一次，每一次计算的window范围是5s内的所有元素。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//每5秒统计一次最近10秒的各个渠道的计数
val windowedStream: WindowedStream[(String, Int), Tuple, TimeWindow] = keyedStream.timeWindow(Time.seconds(10),Time.seconds(5))
val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
<div class="paragraph">
<p>时间间隔可以通过Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。</p>
</div>
<div class="paragraph">
<p>CountWindow
CountWindow根据窗口中相同key元素的数量来触发执行，执行时只计算元素数量达到窗口大小的key对应的结果。
注意：CountWindow的window_size指的是相同Key的元素的个数，不是输入的所有元素的总数。
滚动窗口
默认的CountWindow是一个滚动窗口，只需要指定窗口大小即可，当元素数量达到窗口大小时，就会触发窗口的执行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
 //每当某一个key的个数达到10的时候，显示出来
 val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10)
 val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
<div class="paragraph">
<p>滑动窗口
滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。
下面代码中的sliding_size设置为了2，也就是说，每收到两个相同key的数据就计算一次，每一次计算的window范围是5个元素。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//每当某一个key的个数达到2的时候,触发计算，计算最近该key最近10个元素的内容
val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10,2)
val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第六章_eventtime与window">第六章 EventTime与Window</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_6_1_eventtime的引入">6.1 EventTime的引入</h3>
<div class="paragraph">
<p>在Flink的流式处理中，绝大部分的业务都会使用eventTime，一般只在eventTime无法使用时，才会被迫使用ProcessingTime或者IngestionTime。
如果要使用EventTime，那么需要引入EventTime的时间属性，引入方式如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val env = StreamExecutionEnvironment.getExecutionEnvironment

// 从调用时刻开始给env创建的每一个stream追加时间特征
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_6_2_watermark">6.2 Watermark</h3>
<div class="sect3">
<h4 id="_6_2_1_基本概念">6.2.1 基本概念</h4>
<div class="paragraph">
<p>我们知道，流处理从事件产生，到流经source，再到operator，中间是有一个过程和时间的，虽然大部分情况下，流到operator的数据都是按照事件产生的时间顺序来的，但是也不排除由于网络、分布式等原因，导致乱序的产生，所谓乱序，就是指Flink接收到的事件的先后顺序不是严格按照事件的Event Time顺序排列的。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/stream_watermark_in_order.svg" alt="stream watermark in order">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/stream_watermark_out_of_order.svg" alt="stream watermark out of order">
</div>
</div>
<div class="paragraph">
<p>那么此时出现一个问题，一旦出现乱序，如果只根据eventTime决定window的运行，我们不能明确数据是否全部到位，但又不能无限期的等下去，此时必须要有个机制来保证一个特定的时间后，必须触发window去进行计算了，这个特别的机制，就是Watermark。
Watermark是一种衡量Event Time进展的机制，它是数据本身的一个隐藏属性，数据本身携带着对应的Watermark。
Watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用Watermark机制结合window来实现。
数据流中的Watermark用于表示timestamp小于Watermark的数据，都已经到达了，因此，window的执行也是由Watermark触发的。
Watermark可以理解成一个延迟触发机制，我们可以设置Watermark的延时时长t，每次系统会校验已经到达的数据中最大的maxEventTime，然后认定eventTime小于maxEventTime - t的所有数据都已经到达，如果有窗口的停止时间等于maxEventTime – t，那么这个窗口被触发执行。
有序流的Watermarker如下图所示：（Watermark设置为0）
乱序流的Watermarker如下图所示：（Watermark设置为2）
当Flink接收到每一条数据时，都会产生一条Watermark，这条Watermark就等于当前所有到达数据中的maxEventTime - 延迟时长，也就是说，Watermark是由数据携带的，一旦数据携带的Watermark比当前未触发的窗口的停止时间要晚，那么就会触发相应窗口的执行。由于Watermark是由数据携带的，因此，如果运行过程中无法获取新的数据，那么没有被触发的窗口将永远都不被触发。
上图中，我们设置的允许最大延迟到达时间为2s，所以时间戳为7s的事件对应的Watermark是5s，时间戳为12s的事件的Watermark是10s，如果我们的窗口1是1s<sub>5s，窗口2是6s</sub>10s，那么时间戳为7s的事件到达时的Watermarker恰好触发窗口1，时间戳为12s的事件到达时的Watermark恰好触发窗口2。</p>
</div>
<div class="paragraph">
<p>Watermark 就是触发前一窗口的“关窗时间”，一旦触发关门那么以当前时刻为准在窗口范围内的所有所有数据都会收入窗中。
只要没有达到水位那么不管现实中的时间推进了多久都不会触发关窗。</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_2_2_watermark的引入">6.2.2 Watermark的引入</h4>
<div class="listingblock">
<div class="content">
<pre>val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
  override def extractTimestamp(element: (String, Long, Int)): Long = {

   return  element._2
  }
})</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_6_3_evnettimewindow_api">6.3 EvnetTimeWindow API</h3>
<div class="sect3">
<h4 id="_6_3_1_滚动窗口tumblingeventtimewindows">6.3.1 滚动窗口（TumblingEventTimeWindows）</h4>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
    //  环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val dstream: DataStream[String] = env.socketTextStream("hadoop1",7777)



    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map { text =&gt;
      val arr: Array[String] = text.split(" ")
      (arr(0), arr(1).toLong, 1)
    }
    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
      override def extractTimestamp(element: (String, Long, Int)): Long = {

       return  element._2
      }
    })

    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)
    textKeyStream.print("textkey:")

    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(TumblingEventTimeWindows.of(Time.seconds(2)))

    val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream.fold(new mutable.HashSet[Long]()) { case (set, (key, ts, count)) =&gt;
      set += ts
    }

    groupDstream.print("window::::").setParallelism(1)

    env.execute()

  }

}</pre>
</div>
</div>
<div class="paragraph">
<p>结果是按照Event Time的时间窗口计算得出的，而无关系统的时间（包括输入的快慢）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_2_滑动窗口slidingeventtimewindows">6.3.2 滑动窗口（SlidingEventTimeWindows）</h4>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
  //  环境
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
  env.setParallelism(1)

  val dstream: DataStream[String] = env.socketTextStream("hadoop1",7777)



  val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map { text =&gt;
    val arr: Array[String] = text.split(" ")
    (arr(0), arr(1).toLong, 1)
  }
  val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
    override def extractTimestamp(element: (String, Long, Int)): Long = {

     return  element._2
    }
  })

  val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)
  textKeyStream.print("textkey:")

  val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(SlidingEventTimeWindows.of(Time.seconds(2),Time.milliseconds(500)))

  val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream.fold(new mutable.HashSet[Long]()) { case (set, (key, ts, count)) =&gt;
    set += ts
  }

  groupDstream.print("window::::").setParallelism(1)

  env.execute()

}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_3_会话窗口eventtimesessionwindows">6.3.3 会话窗口（EventTimeSessionWindows）</h4>
<div class="paragraph">
<p>相邻两次数据的EventTime的时间差超过指定的时间间隔就会触发执行。如果加入Watermark， 会在符合窗口触发的情况下进行延迟。到达延迟水位再进行窗口触发。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
    //  环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val dstream: DataStream[String] = env.socketTextStream("hadoop1",7777)

    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map { text =&gt;
      val arr: Array[String] = text.split(" ")
      (arr(0), arr(1).toLong, 1)
    }
    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
      override def extractTimestamp(element: (String, Long, Int)): Long = {

       return  element._2
      }
    })

    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)
    textKeyStream.print("textkey:")

    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(EventTimeSessionWindows.withGap(Time.milliseconds(500)) )

    windowStream.reduce((text1,text2)=&gt;
      (  text1._1,0L,text1._3+text2._3)
    )  .map(_._3).print("windows:::").setParallelism(1)

    env.execute()

  }</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第七章_table_api_与sql">第七章 Table API 与SQL</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Table API是流处理和批处理通用的关系型API，Table API可以基于流输入或者批输入来运行而不需要进行任何修改。Table API是SQL语言的超集并专门为Apache Flink设计的，Table API是Scala 和Java语言集成式的API。与常规SQL语言中将查询指定为字符串不同，Table API查询是以Java或Scala中的语言嵌入样式来定义的，具有IDE支持如:自动完成和语法检测。</p>
</div>
<div class="sect2">
<h3 id="_7_1_需要引入的pom依赖">7.1 需要引入的pom依赖</h3>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-table_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_7_2_构造表环境">7.2 构造表环境</h3>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer("GMALL_STARTUP")
  val dstream: DataStream[String] = env.addSource(myKafkaConsumer)

  val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env)

  val startupLogDstream: DataStream[StartupLog] = dstream.map{ jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) }

  val startupLogTable: Table = tableEnv.fromDataStream(startupLogDstream)

   val table: Table = startupLogTable.select("mid,ch").filter("ch ='appstore'")

  val midchDataStream: DataStream[(String, String)] = table.toAppendStream[(String,String)]

  midchDataStream.print()
  env.execute()
}</pre>
</div>
</div>
<div class="paragraph">
<p>动态表</p>
</div>
<div class="paragraph">
<p>如果流中的数据类型是case class可以直接根据case class的结构生成table
tableEnv.fromDataStream(startupLogDstream)
或者根据字段顺序单独命名
tableEnv.fromDataStream(startupLogDstream,’mid,’uid  &#8230;&#8203;&#8230;&#8203;.)</p>
</div>
<div class="paragraph">
<p>最后的动态表可以转换为流进行输出
table.toAppendStream[(String,String)]</p>
</div>
<div class="paragraph">
<p>字段
 用一个单引放到字段前面 来标识字段名, 如 ‘name , ‘mid ,’amount 等</p>
</div>
</div>
<div class="sect2">
<h3 id="_7_3_通过一个例子_了解tableapi">7.3 通过一个例子 了解TableAPI</h3>
<div class="listingblock">
<div class="content">
<pre>//每10秒中渠道为appstore的个数
def main(args: Array[String]): Unit = {
  //sparkcontext
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  //时间特性改为eventTime
  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

  val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer("GMALL_STARTUP")
  val dstream: DataStream[String] = env.addSource(myKafkaConsumer)

  val startupLogDstream: DataStream[StartupLog] = dstream.map{ jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) }
  //告知watermark 和 eventTime如何提取
  val startupLogWithEventTimeDStream: DataStream[StartupLog] = startupLogDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[StartupLog](Time.seconds(0L)) {
    override def extractTimestamp(element: StartupLog): Long = {
      element.ts
    }
  }).setParallelism(1)

  //SparkSession
  val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env)

  //把数据流转化成Table
  val startupTable: Table = tableEnv.fromDataStream(startupLogWithEventTimeDStream , 'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime)

  //通过table api 进行操作
  // 每10秒 统计一次各个渠道的个数 table api 解决
  //1 groupby  2 要用 window   3 用eventtime来确定开窗时间
  val resultTable: Table = startupTable.window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch,'tt ).select( 'ch, 'ch.count)



  //把Table转化成数据流
  //val appstoreDStream: DataStream[(String, String, Long)] = appstoreTable.toAppendStream[(String,String,Long)]
  val resultDstream: DataStream[(Boolean, (String, Long))] = resultSQLTable.toRetractStream[(String,Long)]

  resultDstream.filter(_._1).print()

  env.execute()

}</pre>
</div>
</div>
<div class="paragraph">
<p>关于group by
如果使用 groupby table转换为流的时候只能用toRetractDstream
  val rDstream: DataStream[(Boolean, (String, Long))] = table.toRetractStream[(String,Long)]</p>
</div>
<div class="paragraph">
<p>toRetractDstream 得到的第一个boolean型字段标识 true就是最新的数据，false表示过期老数据</p>
</div>
<div class="literalblock">
<div class="content">
<pre>val rDstream: DataStream[(Boolean, (String, Long))] = table.toRetractStream[(String,Long)]
rDstream.filter(_._1).print()</pre>
</div>
</div>
<div class="paragraph">
<p>如果使用的api包括时间窗口，那么时间的字段必须，包含在group by中。
  val table: Table = startupLogTable.filter("ch ='appstore'").window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch ,'tt).select("ch,ch.count ")</p>
</div>
<div class="paragraph">
<p>关于时间窗口
用到时间窗口，必须提前声明时间字段，如果是processTime直接在创建动态表时进行追加就可以</p>
</div>
<div class="paragraph">
<p>val startupLogTable: Table = tableEnv.fromDataStream(startupLogWithEtDstream,'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime)</p>
</div>
<div class="paragraph">
<p>如果是EventTime要在创建动态表时声明
val startupLogTable: Table = tableEnv.fromDataStream(startupLogWithEtDstream,'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ps.processtime)</p>
</div>
<div class="paragraph">
<p>滚动窗口可以使用Tumble over 10000.millis on
  val table: Table = startupLogTable.filter("ch ='appstore'").window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch ,'tt).select("ch,ch.count ")</p>
</div>
</div>
<div class="sect2">
<h3 id="_7_4_sql如何编写">7.4 SQL如何编写</h3>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
  //sparkcontext
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  //时间特性改为eventTime
  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

  val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer("GMALL_STARTUP")
  val dstream: DataStream[String] = env.addSource(myKafkaConsumer)

  val startupLogDstream: DataStream[StartupLog] = dstream.map{ jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) }
  //告知watermark 和 eventTime如何提取
  val startupLogWithEventTimeDStream: DataStream[StartupLog] = startupLogDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[StartupLog](Time.seconds(0L)) {
    override def extractTimestamp(element: StartupLog): Long = {
      element.ts
    }
  }).setParallelism(1)

  //SparkSession
  val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env)

  //把数据流转化成Table
  val startupTable: Table = tableEnv.fromDataStream(startupLogWithEventTimeDStream , 'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime)

  //通过table api 进行操作
  // 每10秒 统计一次各个渠道的个数 table api 解决
  //1 groupby  2 要用 window   3 用eventtime来确定开窗时间
  val resultTable: Table = startupTable.window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch,'tt ).select( 'ch, 'ch.count)
 // 通过sql 进行操作

  val resultSQLTable : Table = tableEnv.sqlQuery( "select ch ,count(ch)   from "+startupTable+"  group by ch   ,Tumble(ts,interval '10' SECOND )")

  //把Table转化成数据流
  //val appstoreDStream: DataStream[(String, String, Long)] = appstoreTable.toAppendStream[(String,String,Long)]
  val resultDstream: DataStream[(Boolean, (String, Long))] = resultSQLTable.toRetractStream[(String,Long)]

  resultDstream.filter(_._1).print()

  env.execute()

}</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2019-06-04 14:04:35 +0800
</div>
</div>
</body>
</html>