== 第二章 Flink快速上手

=== 2.1 使用Maven搭建工程

*IDE推荐使用Idea*

我们使用Flink官方提供的flink-quickstart-scala原型来创建我们的工程，因为Flink官方提供的pom.xml经过了精心配置，可以打包出很小的Jar包。

image::quickstart1.png[]

image::quickstart2.png[]

image::quickstart3.png[]

image::quickstart4.png[]

image::quickstart5.png[]

image::quickstart6.png[]

image::quickstart7.png[]

[source,shell]
----
$ tree quickstart/
quickstart/
├── pom.xml
└── src
    └── main
        ├── resources
        │   └── log4j.properties
        └── scala
            └── org
                └── myorg
                    └── quickstart
                        ├── BatchJob.scala
                        └── StreamingJob.scala
----

.StreamingJob.scala
[source, scala]
----
import org.apache.flink.api.java.utils.ParameterTool
import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.api.windowing.time.Time

/**
  * Implements a streaming windowed version of the "WordCount" program.
  *
  * This program connects to a server socket and reads strings from the socket.
  * The easiest way to try this out is to open a text sever (at port 12345)
  * using the ''netcat'' tool via
  * {{{
  * nc -l 12345
  * }}}
  * and run this example with the hostname and the port as arguments..
  */
object StreamingJob {

  /** Main program method */
  def main(args: Array[String]) : Unit = {

    // the host and the port to connect to
    var hostname: String = "localhost"
    var port: Int = 0

    try {
      val params = ParameterTool.fromArgs(args)
      hostname = if (params.has("hostname")) params.get("hostname") else "localhost"
      port = params.getInt("port")
    } catch {
      case e: Exception => {
        System.err.println("No port specified. Please run 'SocketWindowWordCount " +
          "--hostname <hostname> --port <port>', where hostname (localhost by default) and port " +
          "is the address of the text server")
        System.err.println("To start a simple text server, run 'netcat -l <port>' " +
          "and type the input text into the command line")
        return
      }
    }

    // get the execution environment
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    // get input data by connecting to the socket
    val text: DataStream[String] = env.socketTextStream(hostname, port, '\n')

    // parse the data, group it, window it, and aggregate the counts
    val windowCounts = text
      .flatMap { w => w.split("\\s") } // <1>
      .map { w => WordWithCount(w, 1) }
      .keyBy("word")
      .timeWindow(Time.seconds(5))
      .sum("count")

    // print the results with a single thread, rather than in parallel
    windowCounts.print().setParallelism(1)

    env.execute("Socket Window WordCount")
  }

  /** Data type for words with count */
  case class WordWithCount(word: String, count: Long)
}
----
<1> flatMap的函数签名：``def flatMap[A,B](as: List[A])(f: A => List[B]): List[B]``, 例如: ``flatMap(List(1,2,3))(i => List(i,i))``结果是``List(1,1,2,2,3,3)``, ``List("a b", "c d").flatMap(line => line.split(" "))``结果是``List(a, b, c, d)``。

NOTE: 与Flink无关，思考一下如何使用flatMap实现filter？

新建一个Terminal终端，然后运行以下:

[source, shell]
----
$ nc -lk 9999
----

=== 2.2 Flink部署

==== 2.2.1 下载Hadoop Free版本的Flink

:download-link: https://www.apache.org/dyn/closer.lua/flink/flink-1.7.2/flink-1.7.2-bin-scala_2.11.tgz[下载链接]

{download-link}

==== 2.2.2 解压缩

[source,shell]
----
$ tar xvfz flink-1.7.2-bin-scala_2.11.tgz
----

==== 2.2.3 启动Flink集群

[source,shell]
----
$ cd flink-1.7.2
$ ./bin/start-cluster.sh
----

==== 2.2.4 在浏览器中打开Flink的Web UI

http://localhost:8081

==== 2.2.5 打包编写好的StreamingJob程序

在Idea中使用maven package功能打包。

==== 2.2.6 提交打包好的程序

[source,shell]
----
$ ./bin/flink run xxxx.jar
----

==== 2.2.7 在Flink Web UI查看Dashboard中job的执行状态

==== 2.2.8 停止Flink集群

[source,shell]
----
$ ./bin/stop-cluster.sh
----
