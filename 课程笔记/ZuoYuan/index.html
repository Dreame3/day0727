<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.9">
<title>Atguigu Flink Tutorial</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt,.quoteblock .quoteblock{margin:0 0 1.25em;padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>Atguigu Flink Tutorial</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_第一章_flink简介">第一章 Flink简介</a>
<ul class="sectlevel2">
<li><a href="#_1_初识flink">1. 初识Flink</a></li>
<li><a href="#_2_flink的重要特点">2. Flink的重要特点</a>
<ul class="sectlevel3">
<li><a href="#_2_1_事件驱动型event_driven">2.1 事件驱动型(Event-Driven)</a></li>
<li><a href="#_2_2_流与批的世界观">2.2 流与批的世界观</a></li>
<li><a href="#_2_3_分层api">2.3 分层api</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_第二章_flink快速上手">第二章 Flink快速上手</a>
<ul class="sectlevel2">
<li><a href="#_1_使用maven搭建工程">1. 使用Maven搭建工程</a>
<ul class="sectlevel3">
<li><a href="#_1_1_pom_xml文件">1.1 pom.xml文件</a></li>
<li><a href="#_1_2_添加scala文件夹或者将java文件夹rename为scala">1.2 添加scala文件夹或者将java文件夹rename为scala</a></li>
</ul>
</li>
<li><a href="#_2_flink部署">2. Flink部署</a>
<ul class="sectlevel3">
<li><a href="#_1_下载hadoop_free版本的flink">1. 下载Hadoop Free版本的Flink</a></li>
<li><a href="#_2_解压缩">2. 解压缩</a></li>
<li><a href="#_3_启动flink集群">3. 启动Flink集群</a></li>
<li><a href="#_4_在浏览器中打开flink的web_ui">4. 在浏览器中打开Flink的Web UI</a></li>
<li><a href="#_5_编译我们编写好的wordcount程序">5. 编译我们编写好的wordcount程序</a></li>
<li><a href="#_6_提交打包好的程序">6. 提交打包好的程序</a></li>
<li><a href="#_7_在flink_web_ui查看dashboard中job的执行状态">7. 在Flink Web UI查看Dashboard中job的执行状态</a></li>
<li><a href="#_8_停止flink集群">8. 停止Flink集群</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_第三章_flink运行架构">第三章 Flink运行架构</a>
<ul class="sectlevel2">
<li><a href="#_3_1_任务调度原理">3.1 任务调度原理</a></li>
<li><a href="#_3_2_worker与slots">3.2 Worker与Slots</a></li>
<li><a href="#_3_3_程序与数据流">3.3 程序与数据流</a></li>
<li><a href="#_3_4_并行数据流">3.4 并行数据流</a></li>
<li><a href="#_3_5_task与operator_chains">3.5 task与operator chains</a></li>
</ul>
</li>
<li><a href="#_第四章_flink_流处理api">第四章 Flink 流处理Api</a>
<ul class="sectlevel2">
<li><a href="#_4_1_environment">4.1 Environment</a></li>
<li><a href="#_4_2_source">4.2 Source</a></li>
<li><a href="#_4_3_transform">4.3 Transform</a>
<ul class="sectlevel3">
<li><a href="#_4_3_1_map">4.3.1 map</a></li>
<li><a href="#_4_3_2_flatmap">4.3.2 flatMap</a></li>
<li><a href="#_4_3_3_filter">4.3.3 Filter</a></li>
<li><a href="#_4_3_4_keyby">4.3.4 KeyBy</a></li>
<li><a href="#_4_3_5_reduce">4.3.5 Reduce</a></li>
<li><a href="#_4_3_6_split_和_select">4.3.6 Split 和 Select</a></li>
<li><a href="#_4_3_7_connect和comap">4.3.7 Connect和CoMap</a></li>
<li><a href="#_4_3_8_union">4.3.8 Union</a></li>
</ul>
</li>
<li><a href="#_4_4_sink">4.4 Sink</a>
<ul class="sectlevel3">
<li><a href="#_4_4_1_elasticsearch">4.4.1 Elasticsearch</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_第五章_time与window">第五章 Time与Window</a>
<ul class="sectlevel2">
<li><a href="#_5_1_time">5.1 Time</a></li>
<li><a href="#_5_2_window">5.2 Window</a>
<ul class="sectlevel3">
<li><a href="#_5_2_1_window概述">5.2.1 Window概述</a></li>
</ul>
</li>
<li><a href="#_5_3_window_api">5.3 Window API</a></li>
</ul>
</li>
<li><a href="#_第六章_eventtime与window">第六章 EventTime与Window</a>
<ul class="sectlevel2">
<li><a href="#_6_1_eventtime的引入">6.1 EventTime的引入</a></li>
<li><a href="#_6_2_watermark">6.2 Watermark</a>
<ul class="sectlevel3">
<li><a href="#_6_2_1_基本概念">6.2.1 基本概念</a></li>
<li><a href="#_6_2_2_watermark的引入">6.2.2 Watermark的引入</a></li>
</ul>
</li>
<li><a href="#_6_3_evnettimewindow_api">6.3 EvnetTimeWindow API</a>
<ul class="sectlevel3">
<li><a href="#_6_3_1_滚动窗口tumblingeventtimewindows">6.3.1 滚动窗口（TumblingEventTimeWindows）</a></li>
<li><a href="#_6_3_2_滑动窗口slidingeventtimewindows">6.3.2 滑动窗口（SlidingEventTimeWindows）</a></li>
<li><a href="#_6_3_3_会话窗口eventtimesessionwindows">6.3.3 会话窗口（EventTimeSessionWindows）</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_第七章_table_api_与sql">第七章 Table API 与SQL</a>
<ul class="sectlevel2">
<li><a href="#_7_1_需要引入的pom依赖">7.1 需要引入的pom依赖</a></li>
<li><a href="#_7_2_构造表环境">7.2 构造表环境</a></li>
<li><a href="#_7_3_通过一个例子_了解tableapi">7.3 通过一个例子 了解TableAPI</a></li>
<li><a href="#_7_4_sql如何编写">7.4 SQL如何编写</a></li>
</ul>
</li>
<li><a href="#_第八章_dataflow模型">第八章 Dataflow模型</a>
<ul class="sectlevel2">
<li><a href="#_8_0_摘要">8.0 摘要</a></li>
<li><a href="#_8_1_简介">8.1 简介</a>
<ul class="sectlevel3">
<li><a href="#_8_1_1_无边界有边界与流处理批处理">8.1.1   无边界、有边界与流处理、批处理</a></li>
<li><a href="#_8_1_2_窗口">8.1.2 窗口</a></li>
<li><a href="#_8_1_3_时间域">8.1.3 时间域</a></li>
</ul>
</li>
<li><a href="#_8_2_dataflow模型">8.2 DataFlow模型</a>
<ul class="sectlevel3">
<li><a href="#_8_2_1_核心编程模型">8.2.1 核心编程模型</a></li>
<li><a href="#_8_2_2_窗口">8.2.2 窗口</a>
<ul class="sectlevel4">
<li><a href="#_8_2_2_1_窗口分配">8.2.2.1 窗口分配</a></li>
<li><a href="#_8_2_2_2_窗口合并">8.2.2.2 窗口合并</a></li>
<li><a href="#_8_2_2_3_api">8.2.2.3 API</a></li>
</ul>
</li>
<li><a href="#_8_2_3_触发器和增量处理">8.2.3 触发器和增量处理</a></li>
</ul>
</li>
<li><a href="#_8_3_实现和设计">8.3 实现和设计</a>
<ul class="sectlevel3">
<li><a href="#_8_3_1_实现">8.3.1 实现</a></li>
<li><a href="#_8_3_2_设计原则">8.3.2 设计原则</a></li>
<li><a href="#_8_3_3_业务场景">8.3.3 业务场景</a>
<ul class="sectlevel4">
<li><a href="#_8_3_3_1_大规模数据回写和lambda架构统一模型">8.3.3.1 大规模数据回写和Lambda架构；统一模型</a></li>
<li><a href="#_8_3_3_2_非对齐窗口会话">8.3.3.2 非对齐窗口：会话</a></li>
<li><a href="#_8_3_3_3_支付触发器累加和撤回">8.3.3.3 支付：触发器，累加和撤回</a></li>
<li><a href="#_8_3_3_4_统计计算水位线触发器">8.3.3.4 统计计算：水位线触发器</a></li>
<li><a href="#_8_3_3_5_推荐处理时间触发器">8.3.3.5 推荐：处理时间触发器</a></li>
<li><a href="#_8_3_3_6_异常探测数据驱动和组合触发器">8.3.3.6 异常探测：数据驱动和组合触发器</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_8_4_总结">8.4 总结</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="imageblock">
<div class="content">
<img src="images/atguigu.jpeg" alt="atguigu" width="300" height="200">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第一章_flink简介">第一章 Flink简介</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_初识flink">1. 初识Flink</h3>
<div class="paragraph">
<p>Flink起源于Stratosphere项目，Stratosphere是在2010~2014年由3所地处柏林的大学和欧洲的一些其他的大学共同进行的研究项目，2014年4月Stratosphere的代码被复制并捐赠给了Apache软件基金会，参加这个孵化项目的初始成员是Stratosphere系统的核心开发人员，2014年12月，Flink一跃成为Apache软件基金会的顶级项目。</p>
</div>
<div class="paragraph">
<p>在德语中，Flink一词表示快速和灵巧，项目采用一只松鼠的彩色图案作为logo，这不仅是因为松鼠具有快速和灵巧的特点，还因为柏林的松鼠有一种迷人的红棕色，而Flink的松鼠logo拥有可爱的尾巴，尾巴的颜色与Apache软件基金会的logo颜色相呼应，也就是说，这是一只Apache风格的松鼠。</p>
</div>
<div class="openblock float-group">
<div class="content">
<div class="imageblock left">
<div class="content">
<img src="images/ASF20thAnniversary.jpg" alt="ASF20thAnniversary" width="300" height="200">
</div>
<div class="title">Figure 1. apache logo</div>
</div>
<div class="imageblock left">
<div class="content">
<img src="images/flink-header-logo.svg" alt="flink header logo" width="300" height="200">
</div>
<div class="title">Figure 2. apache flink logo</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Flink主页在其顶部展示了该项目的理念: "<span class="red">Apache Flink是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源流处理框架</span>"。</p>
</div>
<div class="paragraph">
<p>Apache Flink是一个框架和分布式处理引擎，<span class="red">用于对无界和有界数据流进行有状态计算</span>。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/flink-home-graphic.png" alt="flink home graphic">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_flink的重要特点">2. Flink的重要特点</h3>
<div class="sect3">
<h4 id="_2_1_事件驱动型event_driven">2.1 事件驱动型(Event-Driven)</h4>
<div class="paragraph">
<p>事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。比较典型的就是以Kafka为代表的消息队列几乎都是事件驱动型应用。</p>
</div>
<div class="paragraph">
<p>与之不同的就是Spark Streaming微批次，如图：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/streaming-flow.png" alt="streaming flow">
</div>
</div>
<div class="paragraph">
<p>事件驱动型：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/usecases-eventdrivenapps.png" alt="usecases eventdrivenapps">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_2_2_流与批的世界观">2.2 流与批的世界观</h4>
<div class="paragraph">
<p><strong>批处理</strong>的特点是有界、持久、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。</p>
</div>
<div class="paragraph">
<p><strong>流处理</strong>的特点是无界、实时，无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。</p>
</div>
<div class="paragraph">
<p>在Spark的世界观中，一切都是由批次组成的，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。</p>
</div>
<div class="paragraph">
<p>而在Flink的世界观中，一切都是由流组成的，离线数据是有界限的流，实时数据是一个没有界限的流，这就是所谓的有界流和无界流。</p>
</div>
<div class="paragraph">
<p><strong>无界数据流</strong>：无界数据流有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序(例如事件发生的顺序)获取event，以便能够推断结果完整性。</p>
</div>
<div class="paragraph">
<p><strong>有界数据流</strong>：有界数据流有明确定义的开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bounded-unbounded.png" alt="bounded unbounded">
</div>
</div>
<div class="paragraph">
<p><span class="red">这种以流为世界观的架构，获得的最大好处就是具有极低的延迟。</span></p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_分层api">2.3 分层api</h4>
<div class="imageblock">
<div class="content">
<img src="images/api-stack.png" alt="api stack">
</div>
</div>
<div class="paragraph">
<p>最底层级的抽象仅仅提供了有状态流，它将通过在DataStream API中嵌入Process Function来处理数据。Process Function与DataStream API相集成，使其可以对某些特定的操作进行底层的抽象，它允许用户可以自由地处理来自一个或多个数据流的事件，并使用一致的容错的状态。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以处理复杂的计算。</p>
</div>
<div class="paragraph">
<p>实际上，大多数应用并不需要上述的底层抽象，而是针对核心API(Core APIs)进行编程，比如DataStream API(有界或无界流数据)以及DataSet API(有界数据集)。这些API为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换(transformations)，连接(joins)，聚合(aggregations)，窗口操作(window)等等。DataSet API为有界数据集提供了额外的支持，例如循环与迭代。这些API处理的数据类型以类(classes)的形式由各自的编程语言所表示。</p>
</div>
<div class="paragraph">
<p>Table API是以表为中心的声明式编程，其中表可能会动态变化(在表达流数据时)。Table API遵循(扩展的)关系模型：表有二维数据结构(schema)(类似于关系数据库中的表)，同时API提供与RDBMS相似的操作，例如select、project、join、group-by、aggregate等。Table API程序声明式地定义了什么逻辑操作应该执行，而不是准确地确定这些操作代码看上去如何(过程式编程风格)。尽管Table API可以通过多种类型的用户自定义函数(UDF)进行扩展，其仍不如核心API更具表达能力，但是使用起来却更加简洁(代码量更少)。除此之外，Table API程序在执行之前会经过内置优化器进行优化。</p>
</div>
<div class="paragraph">
<p>你可以在表与DataStream/DataSet之间无缝切换，以允许程序将Table API与DataStream以及DataSet混合使用。</p>
</div>
<div class="paragraph">
<p>Flink提供的最高层级的抽象是SQL。这一层抽象在语法与表达能力上与Table API类似，但是是以SQL查询表达式的形式表现程序。SQL抽象与Table API交互密切，同时SQL查询可以直接在Table API定义的表上执行。</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
目前Flink作为批处理还不是主流，不如Spark成熟，所以DataSet使用的并不是很多。Flink Table API和Flink SQL也并不完善，大多都由各大厂商自己定制。所以我们主要学习DataStream API的使用。实际上Flink作为最接近Google DataFlow模型的实现，是流批统一的观点，所以基本上使用DataStream就可以了，DataSet并不是很地道。
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第二章_flink快速上手">第二章 Flink快速上手</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_使用maven搭建工程">1. 使用Maven搭建工程</h3>
<div class="paragraph">
<p><strong>IDE推荐Idea</strong></p>
</div>
<div class="sect3">
<h4 id="_1_1_pom_xml文件">1.1 pom.xml文件</h4>
<div class="listingblock">
<div class="title">pom.xml</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="xml"><span></span><span class="tok-cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="tok-nt">&lt;project</span> <span class="tok-na">xmlns=</span><span class="tok-s">&quot;http://maven.apache.org/POM/4.0.0&quot;</span>
         <span class="tok-na">xmlns:xsi=</span><span class="tok-s">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span>
         <span class="tok-na">xsi:schemaLocation=</span><span class="tok-s">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span><span class="tok-nt">&gt;</span>
    <span class="tok-nt">&lt;modelVersion&gt;</span>4.0.0<span class="tok-nt">&lt;/modelVersion&gt;</span>

    <span class="tok-nt">&lt;groupId&gt;</span>com.atguigu.flink<span class="tok-nt">&lt;/groupId&gt;</span>
    <span class="tok-nt">&lt;artifactId&gt;</span>flink<span class="tok-nt">&lt;/artifactId&gt;</span>
    <span class="tok-nt">&lt;version&gt;</span>1.0-SNAPSHOT<span class="tok-nt">&lt;/version&gt;</span>

    <span class="tok-nt">&lt;dependencies&gt;</span>
        <span class="tok-nt">&lt;dependency&gt;</span>
            <span class="tok-nt">&lt;groupId&gt;</span>org.apache.flink<span class="tok-nt">&lt;/groupId&gt;</span>
            <span class="tok-nt">&lt;artifactId&gt;</span>flink-scala_2.11<span class="tok-nt">&lt;/artifactId&gt;</span>
            <span class="tok-nt">&lt;version&gt;</span>1.7.0<span class="tok-nt">&lt;/version&gt;</span>
        <span class="tok-nt">&lt;/dependency&gt;</span>

        <span class="tok-c">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-scala --&gt;</span>
        <span class="tok-nt">&lt;dependency&gt;</span>
            <span class="tok-nt">&lt;groupId&gt;</span>org.apache.flink<span class="tok-nt">&lt;/groupId&gt;</span>
            <span class="tok-nt">&lt;artifactId&gt;</span>flink-streaming-scala_2.11<span class="tok-nt">&lt;/artifactId&gt;</span>
            <span class="tok-nt">&lt;version&gt;</span>1.7.0<span class="tok-nt">&lt;/version&gt;</span>
        <span class="tok-nt">&lt;/dependency&gt;</span>
    <span class="tok-nt">&lt;/dependencies&gt;</span>

    <span class="tok-nt">&lt;build&gt;</span>
        <span class="tok-nt">&lt;plugins&gt;</span>
            <span class="tok-c">&lt;!-- 该插件用于将Scala代码编译成class文件 --&gt;</span>
            <span class="tok-nt">&lt;plugin&gt;</span>
                <span class="tok-nt">&lt;groupId&gt;</span>net.alchim31.maven<span class="tok-nt">&lt;/groupId&gt;</span>
                <span class="tok-nt">&lt;artifactId&gt;</span>scala-maven-plugin<span class="tok-nt">&lt;/artifactId&gt;</span>
                <span class="tok-nt">&lt;version&gt;</span>3.4.6<span class="tok-nt">&lt;/version&gt;</span>
                <span class="tok-nt">&lt;executions&gt;</span>
                    <span class="tok-nt">&lt;execution&gt;</span>
                        <span class="tok-c">&lt;!-- 声明绑定到maven的compile阶段 --&gt;</span>
                        <span class="tok-nt">&lt;goals&gt;</span>

                            <span class="tok-nt">&lt;goal&gt;</span>testCompile<span class="tok-nt">&lt;/goal&gt;</span>
                        <span class="tok-nt">&lt;/goals&gt;</span>
                    <span class="tok-nt">&lt;/execution&gt;</span>
                <span class="tok-nt">&lt;/executions&gt;</span>
            <span class="tok-nt">&lt;/plugin&gt;</span>

            <span class="tok-nt">&lt;plugin&gt;</span>
                <span class="tok-nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="tok-nt">&lt;/groupId&gt;</span>
                <span class="tok-nt">&lt;artifactId&gt;</span>maven-assembly-plugin<span class="tok-nt">&lt;/artifactId&gt;</span>
                <span class="tok-nt">&lt;version&gt;</span>3.0.0<span class="tok-nt">&lt;/version&gt;</span>
                <span class="tok-nt">&lt;configuration&gt;</span>
                    <span class="tok-nt">&lt;descriptorRefs&gt;</span>
                        <span class="tok-nt">&lt;descriptorRef&gt;</span>jar-with-dependencies<span class="tok-nt">&lt;/descriptorRef&gt;</span>
                    <span class="tok-nt">&lt;/descriptorRefs&gt;</span>
                <span class="tok-nt">&lt;/configuration&gt;</span>
                <span class="tok-nt">&lt;executions&gt;</span>
                    <span class="tok-nt">&lt;execution&gt;</span>
                        <span class="tok-nt">&lt;id&gt;</span>make-assembly<span class="tok-nt">&lt;/id&gt;</span>
                        <span class="tok-nt">&lt;phase&gt;</span>package<span class="tok-nt">&lt;/phase&gt;</span>
                        <span class="tok-nt">&lt;goals&gt;</span>
                            <span class="tok-nt">&lt;goal&gt;</span>single<span class="tok-nt">&lt;/goal&gt;</span>
                        <span class="tok-nt">&lt;/goals&gt;</span>
                    <span class="tok-nt">&lt;/execution&gt;</span>
                <span class="tok-nt">&lt;/executions&gt;</span>
            <span class="tok-nt">&lt;/plugin&gt;</span>
        <span class="tok-nt">&lt;/plugins&gt;</span>
    <span class="tok-nt">&lt;/build&gt;</span>

<span class="tok-nt">&lt;/project&gt;</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_1_2_添加scala文件夹或者将java文件夹rename为scala">1.2 添加scala文件夹或者将java文件夹rename为scala</h4>
<div class="listingblock">
<div class="title">StreamWcApp.scala</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">import</span> <span class="tok-nn">org.apache.flink.streaming.api.scala.</span><span class="tok-o">{</span><span class="tok-nc">DataStream</span><span class="tok-o">,</span> <span class="tok-nc">StreamExecutionEnvironment</span><span class="tok-o">}</span>

<span class="tok-k">object</span> <span class="tok-nc">StreamWcApp</span> <span class="tok-o">{</span>

  <span class="tok-k">def</span> <span class="tok-n">main</span><span class="tok-o">(</span><span class="tok-n">args</span><span class="tok-k">:</span> <span class="tok-kt">Array</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">])</span><span class="tok-k">:</span> <span class="tok-kt">Unit</span> <span class="tok-o">=</span> <span class="tok-o">{</span>
    <span class="tok-c1">//创建流处理环境</span>
    <span class="tok-k">val</span> <span class="tok-n">env</span><span class="tok-k">:</span> <span class="tok-kt">StreamExecutionEnvironment</span> <span class="tok-o">=</span> <span class="tok-nc">StreamExecutionEnvironment</span><span class="tok-o">.</span><span class="tok-n">getExecutionEnvironment</span>
    <span class="tok-c1">//接收socket文本流</span>
    <span class="tok-k">val</span> <span class="tok-n">textDstream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">env</span><span class="tok-o">.</span><span class="tok-n">socketTextStream</span><span class="tok-o">(</span><span class="tok-s">&quot;localhost&quot;</span><span class="tok-o">,</span> <span class="tok-mi">9000</span><span class="tok-o">,</span> <span class="tok-s">&quot;\n&quot;</span><span class="tok-o">)</span>

    <span class="tok-c1">// flatMap和Map需要引用的隐式转换</span>
    <span class="tok-k">import</span> <span class="tok-nn">org.apache.flink.api.scala._</span>
    <span class="tok-c1">// 处理, 分组并且sum聚合</span>
    <span class="tok-k">val</span> <span class="tok-n">dStream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[(</span><span class="tok-kt">String</span>, <span class="tok-kt">Int</span><span class="tok-o">)]</span> <span class="tok-k">=</span> <span class="tok-n">textDstream</span>
        <span class="tok-c1">// 使用空白符进行切割，并且遍历每一个单词</span>
        <span class="tok-o">.</span><span class="tok-n">flatMap</span><span class="tok-o">(</span><span class="tok-k">_</span><span class="tok-o">.</span><span class="tok-n">split</span><span class="tok-o">(</span><span class="tok-s">&quot;\\s&quot;</span><span class="tok-o">))</span>
        <span class="tok-c1">// 过滤出非空</span>
        <span class="tok-o">.</span><span class="tok-n">filter</span><span class="tok-o">(</span><span class="tok-k">_</span><span class="tok-o">.</span><span class="tok-n">nonEmpty</span><span class="tok-o">)</span>
        <span class="tok-c1">// 这一步实现了mr中的map</span>
        <span class="tok-o">.</span><span class="tok-n">map</span><span class="tok-o">((</span><span class="tok-k">_</span><span class="tok-o">,</span> <span class="tok-mi">1</span><span class="tok-o">))</span>
        <span class="tok-c1">// 使用第0个元素为key进行聚合</span>
        <span class="tok-o">.</span><span class="tok-n">keyBy</span><span class="tok-o">(</span><span class="tok-mi">0</span><span class="tok-o">)</span>
        <span class="tok-c1">// tumbling window: 滚动窗口, [9:00:00, 9:00:05), [9:00:05, 9:00:10)</span>
        <span class="tok-o">.</span><span class="tok-n">timeWindow</span><span class="tok-o">(</span><span class="tok-nc">Time</span><span class="tok-o">.</span><span class="tok-n">seconds</span><span class="tok-o">(</span><span class="tok-mi">5</span><span class="tok-o">))</span>
        <span class="tok-c1">// 实现了mr的reduce语义</span>
        <span class="tok-o">.</span><span class="tok-n">sum</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">)</span>

    <span class="tok-c1">// 打印</span>
    <span class="tok-n">dStream</span><span class="tok-o">.</span><span class="tok-n">print</span><span class="tok-o">()</span>

    <span class="tok-n">env</span><span class="tok-o">.</span><span class="tok-n">execute</span><span class="tok-o">()</span>
  <span class="tok-o">}</span>
<span class="tok-o">}</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>nc -lk <span class="tok-m">9999</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_flink部署">2. Flink部署</h3>
<div class="sect3">
<h4 id="_1_下载hadoop_free版本的flink">1. 下载Hadoop Free版本的Flink</h4>
<div class="paragraph">
<p><a href="https://www.apache.org/dyn/closer.lua/flink/flink-1.7.2/flink-1.7.2-bin-scala_2.11.tgz">下载链接</a></p>
</div>
</div>
<div class="sect3">
<h4 id="_2_解压缩">2. 解压缩</h4>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>$ tar xvfz flink-1.7.2-bin-scala_2.11.tgz</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_3_启动flink集群">3. 启动Flink集群</h4>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>$ <span class="tok-nb">cd</span> flink-1.7.2
$ ./bin/start-cluster.sh</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_在浏览器中打开flink的web_ui">4. 在浏览器中打开Flink的Web UI</h4>
<div class="paragraph">
<p><a href="http://localhost:8081" class="bare">http://localhost:8081</a></p>
</div>
</div>
<div class="sect3">
<h4 id="_5_编译我们编写好的wordcount程序">5. 编译我们编写好的wordcount程序</h4>
<div class="paragraph">
<p>在Idea中使用maven package功能打包。</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_提交打包好的程序">6. 提交打包好的程序</h4>
<div class="paragraph">
<p>$ ./bin/flink run -c xxxx.jar</p>
</div>
</div>
<div class="sect3">
<h4 id="_7_在flink_web_ui查看dashboard中job的执行状态">7. 在Flink Web UI查看Dashboard中job的执行状态</h4>

</div>
<div class="sect3">
<h4 id="_8_停止flink集群">8. 停止Flink集群</h4>
<div class="paragraph">
<p>$ ./bin/stop-cluster.sh</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第三章_flink运行架构">第三章 Flink运行架构</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_3_1_任务调度原理">3.1 任务调度原理</h3>
<div class="imageblock">
<div class="content">
<img src="images/processes.svg" alt="processes">
</div>
</div>
<div class="paragraph">
<p>客户端不是运行时和程序执行的一部分，但它用于准备并发送Dataflow(JobGraph)给Master(JobManager)，然后，客户端断开连接或者维持连接以等待接收计算结果。</p>
</div>
<div class="paragraph">
<p>当Flink集群启动后，首先会启动一个JobManger和一个或多个的TaskManager。由Client提交任务给JobManager，JobManager再调度任务到各个TaskManager去执行，然后TaskManager将心跳和统计信息汇报给JobManager。TaskManager之间以流的形式进行数据的传输。上述三者均为独立的JVM进程。</p>
</div>
<div class="paragraph">
<p>Client为提交Job的客户端，可以运行在任何机器上(与JobManager环境连通即可)。提交Job后，Client可以结束进程(Streaming的任务)，也可以不结束并等待结果返回。</p>
</div>
<div class="paragraph">
<p>JobManager主要负责调度Job并协调Task做checkpoint。从Client处接收到Job和JAR包等资源后，会生成优化后的执行计划，并以Task为单元调度到各个TaskManager去执行。</p>
</div>
<div class="paragraph">
<p>TaskManager在启动的时候就设置好了槽位数(Slot)，每个Slot能启动一个Task，Task为线程。从JobManager处接收需要部署的Task，部署启动后，与自己的上游建立Netty连接，接收数据并处理。</p>
</div>
<div class="paragraph">
<p><strong>关于执行图</strong></p>
</div>
<div class="paragraph">
<p>Flink中的执行图可以分成四层：StreamGraph &#8594; JobGraph &#8594; ExecutionGraph &#8594; 物理执行图。</p>
</div>
<div class="paragraph">
<p><strong>StreamGraph</strong>：是根据用户通过Stream API编写的代码生成的最初的图。用来表示程序的拓扑结构。</p>
</div>
<div class="paragraph">
<p><strong>JobGraph</strong>：StreamGraph经过优化后生成了JobGraph，提交给JobManager的数据结构。主要的优化为，将多个符合条件的节点chain在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。</p>
</div>
<div class="paragraph">
<p><strong>ExecutionGraph</strong>：JobManager根据JobGraph生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。</p>
</div>
<div class="paragraph">
<p><strong>物理执行图</strong>：JobManager根据ExecutionGraph对Job进行调度后，在各个TaskManager上部署Task后形成的"图"，并不是一个具体的数据结构。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/jobgraph.png" alt="jobgraph">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_3_2_worker与slots">3.2 Worker与Slots</h3>
<div class="paragraph">
<p>每一个worker(TaskManager)是一个JVM进程，它可能会在独立的线程上执行一个或多个subtask。为了控制一个worker能接收多少个task，worker通过task slot来进行控制(一个worker至少有一个task slot)。</p>
</div>
<div class="paragraph">
<p>每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个subtask将不需要跟来自其他job的subtask竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。</p>
</div>
<div class="paragraph">
<p>通过调整task slot的数量，允许用户定义subtask之间如何互相隔离。如果一个TaskManager一个slot，那将意味着每个task group运行在独立的JVM中(该JVM可能是通过一个特定的容器启动的)，而一个TaskManager多个slot意味着更多的subtask可以共享同一个JVM。而在同一个JVM进程中的task将共享TCP连接(基于IO多路复用)和心跳消息。它们也可能共享数据集和数据结构，因此这减少了每个task的负载。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/tasks_slots.svg" alt="tasks slots">
</div>
</div>
<div class="paragraph">
<p>Task Slot是静态的概念，是指TaskManager具有的并发执行能力，可以通过参数taskmanager.numberOfTaskSlots进行配置，而并行度parallelism是动态概念，即TaskManager运行程序时实际使用的并发能力，可以通过参数parallelism.default进行配置。</p>
</div>
<div class="paragraph">
<p>也就是说，假设一共有3个TaskManager，每一个TaskManager中的分配3个Task Slot，也就是每个TaskManager可以接收3个task，一共9个Task Slot，如果我们设置parallelism.default=1，即运行程序默认的并行度为1，9个TaskSlot只用了1个，有8个空闲，因此，设置合适的并行度才能提高效率。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/slots_parallelism.svg" alt="slots parallelism">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_3_3_程序与数据流">3.3 程序与数据流</h3>
<div class="imageblock">
<div class="content">
<img src="images/program_dataflow.svg" alt="program dataflow">
</div>
</div>
<div class="paragraph">
<p>所有的Flink程序都是由三部分组成的：Source、Transformation和Sink。</p>
</div>
<div class="paragraph">
<p>Source负责读取数据源，Transformation利用各种算子进行处理加工，Sink负责输出。</p>
</div>
<div class="paragraph">
<p>在运行时，Flink上运行的程序会被映射成Streaming Dataflows，它包含了这三部分。每一个Dataflow以一个或多个sources开始以一个或多个sinks结束。dataflow类似于任意的有向无环图(DAG)，当然特定形式的环可以通过iteration构建。在大部分情况下，程序中的transformations跟dataflow中的operator是一一对应的关系，但有时候，一个transformation可能对应多个operator。</p>
</div>
</div>
<div class="sect2">
<h3 id="_3_4_并行数据流">3.4 并行数据流</h3>
<div class="paragraph">
<p>Flink程序的执行具有并行、分布式的特性。在执行过程中，一个 stream 包含一个或多个 stream partition ，而每一个 operator 包含一个或多个 operator subtask，这些operator subtasks在不同的线程、不同的物理机或不同的容器中彼此互不依赖得执行。
一个特定operator的subtask的个数被称之为其parallelism(并行度)。一个stream的并行度总是等同于其producing operator的并行度。一个程序中，不同的operator可能具有不同的并行度。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/parallel_dataflow.svg" alt="parallel dataflow">
</div>
</div>
<div class="paragraph">
<p>Stream在operator之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式，具体是哪一种形式，取决于operator的种类。
One-to-one：stream(比如在source和map operator之间)维护着分区以及元素的顺序。那意味着map operator的subtask看到的元素的个数以及顺序跟source operator的subtask生产的元素的个数、顺序相同，map、fliter、flatMap等算子都是one-to-one的对应关系。
类似于spark中的窄依赖
Redistributing：stream(map()跟keyBy/window之间或者keyBy/window跟sink之间)的分区会发生改变。每一个operator subtask依据所选择的transformation发送数据到不同的目标subtask。例如，keyBy() 基于hashCode重分区、broadcast和rebalance会随机重新分区，这些算子都会引起redistribute过程，而redistribute过程就类似于Spark中的shuffle过程。
类似于spark中的宽依赖</p>
</div>
</div>
<div class="sect2">
<h3 id="_3_5_task与operator_chains">3.5 task与operator chains</h3>
<div class="paragraph">
<p>相同并行度的one to one操作，Flink这样相连的operator链接在一起形成一个task，原来的operator成为里面的subtask。将operators链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/operatorschains.png" alt="operatorschains">
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第四章_flink_流处理api">第四章 Flink 流处理Api</h2>
<div class="sectionbody">
<div class="paragraph">
<p>environment &#8594; source &#8594; transform &#8594; sink</p>
</div>
<div class="sect2">
<h3 id="_4_1_environment">4.1 Environment</h3>
<div class="paragraph">
<p>getExecutionEnvironment</p>
</div>
<div class="paragraph">
<p>创建一个执行环境，表示当前执行程序的上下文。如果程序是独立调用的，则此方法返回本地执行环境；如果从命令行客户端调用程序以提交到集群，则此方法返回此集群的执行环境，也就是说，getExecutionEnvironment会根据查询运行的方式决定返回什么样的运行环境，是最常用的一种创建执行环境的方式。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">val</span> <span class="tok-n">env</span><span class="tok-k">:</span> <span class="tok-kt">ExecutionEnvironment</span> <span class="tok-o">=</span> <span class="tok-nc">ExecutionEnvironment</span><span class="tok-o">.</span><span class="tok-n">getExecutionEnvironment</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>如果没有设置并行度，会以flink-conf.yaml中的配置为准，默认是1</p>
</div>
<div class="paragraph">
<p>createLocalEnvironment
返回本地执行环境，需要在调用时指定默认的并行度。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">val</span> <span class="tok-n">env</span> <span class="tok-k">=</span> <span class="tok-nc">StreamExecutionEnvironment</span><span class="tok-o">.</span><span class="tok-n">createLocalEnvironment</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>createRemoteEnvironment
返回集群执行环境，将Jar提交到远程服务器。需要在调用时指定JobManager的IP和端口号，并指定要在集群中运行的Jar包。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">val</span> <span class="tok-n">env</span> <span class="tok-k">=</span> <span class="tok-nc">ExecutionEnvironment</span><span class="tok-o">.</span><span class="tok-n">createRemoteEnvironment</span><span class="tok-o">(</span><span class="tok-s">&quot;node&quot;</span><span class="tok-o">,</span> <span class="tok-mi">6123</span><span class="tok-o">,</span><span class="tok-s">&quot;C://jar//flink//wordcount.jar&quot;</span><span class="tok-o">)</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_2_source">4.2 Source</h3>
<div class="paragraph">
<p>创建Kafka工具类</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">object</span> <span class="tok-nc">MyKafkaUtil</span> <span class="tok-o">{</span>

  <span class="tok-k">val</span> <span class="tok-n">prop</span> <span class="tok-k">=</span> <span class="tok-k">new</span> <span class="tok-nc">Properties</span><span class="tok-o">()</span>

  <span class="tok-n">prop</span><span class="tok-o">.</span><span class="tok-n">setProperty</span><span class="tok-o">(</span><span class="tok-s">&quot;bootstrap.servers&quot;</span><span class="tok-o">,</span><span class="tok-s">&quot;hadoop1:9092&quot;</span><span class="tok-o">)</span>
  <span class="tok-n">prop</span><span class="tok-o">.</span><span class="tok-n">setProperty</span><span class="tok-o">(</span><span class="tok-s">&quot;group.id&quot;</span><span class="tok-o">,</span><span class="tok-s">&quot;gmall&quot;</span><span class="tok-o">)</span>

  <span class="tok-k">def</span> <span class="tok-n">getConsumer</span><span class="tok-o">(</span><span class="tok-n">topic</span><span class="tok-k">:</span><span class="tok-kt">String</span> <span class="tok-o">)</span><span class="tok-k">:</span><span class="tok-kt">FlinkKafkaConsumer011</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">]</span><span class="tok-k">=</span> <span class="tok-o">{</span>
      <span class="tok-k">val</span> <span class="tok-n">myKafkaConsumer</span><span class="tok-k">:</span><span class="tok-kt">FlinkKafkaConsumer011</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-k">new</span> <span class="tok-nc">FlinkKafkaConsumer011</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">](</span><span class="tok-n">topic</span><span class="tok-o">,</span> <span class="tok-k">new</span> <span class="tok-nc">SimpleStringSchema</span><span class="tok-o">(),</span> <span class="tok-n">prop</span><span class="tok-o">)</span>
     <span class="tok-n">myKafkaConsumer</span>
  <span class="tok-o">}</span>
<span class="tok-o">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>增加业务主类StartupApp</p>
</div>
<div class="listingblock">
<div class="content">
<pre>object StartupApp {
    def main(args: Array[String]): Unit = {
        val environment: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

        val kafkaConsumer  =MyKafkaUtil.getConsumer("GMALL_STARTUP")

        val dstream: DataStream[String] = environment.addSource(kafkaConsumer)

        dstream.print()

        environment.execute()
    }
}</pre>
</div>
</div>
<div class="paragraph">
<p>Flink+Kafka是如何实现exactly-once语义的</p>
</div>
<div class="paragraph">
<p>Flink通过checkpoint来保存数据是否处理完成的状态</p>
</div>
<div class="paragraph">
<p>由JobManager协调各个TaskManager进行checkpoint存储，checkpoint保存在 StateBackend中，默认StateBackend是内存级的，也可以改为文件级的进行持久化保存。</p>
</div>
<div class="paragraph">
<p>执行过程实际上是一个两段式提交，每个算子执行完成，会进行“预提交”，直到执行完sink操作，会发起“确认提交”，如果执行失败，预提交会放弃掉。
如果宕机需要通过StateBackend进行恢复，只能恢复所有确认提交的操作。</p>
</div>
<div class="paragraph">
<p><a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html" class="bare">https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html</a></p>
</div>
<div class="paragraph">
<p>文档</p>
</div>
</div>
<div class="sect2">
<h3 id="_4_3_transform">4.3 Transform</h3>
<div class="paragraph">
<p>转换算子</p>
</div>
<div class="sect3">
<h4 id="_4_3_1_map">4.3.1 map</h4>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">val</span> <span class="tok-n">streamMap</span> <span class="tok-k">=</span> <span class="tok-n">stream</span><span class="tok-o">.</span><span class="tok-n">map</span> <span class="tok-o">{</span> <span class="tok-n">x</span> <span class="tok-k">=&gt;</span> <span class="tok-n">x</span> <span class="tok-o">*</span> <span class="tok-mi">2</span> <span class="tok-o">}</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_2_flatmap">4.3.2 flatMap</h4>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">val</span> <span class="tok-n">streamFlatMap</span> <span class="tok-k">=</span> <span class="tok-n">stream</span><span class="tok-o">.</span><span class="tok-n">flatMap</span><span class="tok-o">{</span>
  <span class="tok-n">x</span> <span class="tok-k">=&gt;</span> <span class="tok-n">x</span><span class="tok-o">.</span><span class="tok-n">split</span><span class="tok-o">(</span><span class="tok-s">&quot; &quot;</span><span class="tok-o">)</span>
<span class="tok-o">}</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_3_filter">4.3.3 Filter</h4>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-k">val</span> <span class="tok-n">streamFilter</span> <span class="tok-k">=</span> <span class="tok-n">stream</span><span class="tok-o">.</span><span class="tok-n">filter</span><span class="tok-o">{</span>
  <span class="tok-n">x</span> <span class="tok-k">=&gt;</span> <span class="tok-n">x</span> <span class="tok-o">==</span> <span class="tok-mi">1</span>
<span class="tok-o">}</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_4_keyby">4.3.4 KeyBy</h4>
<div class="paragraph">
<p>DataStream → KeyedStream：输入必须是Tuple类型，逻辑地将一个流拆分成不相交的分区，每个分区包含具有相同key的元素，在内部以hash的形式实现的。</p>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_5_reduce">4.3.5 Reduce</h4>
<div class="paragraph">
<p>KeyedStream → DataStream：一个分组数据流的聚合操作，合并当前的元素和上次聚合的结果，产生一个新的值，返回的流中包含每一次聚合的结果，而不是只返回最后一次聚合的最终结果。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-c1">//求各个渠道的累计个数</span>
<span class="tok-k">val</span> <span class="tok-n">startUplogDstream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">dstream</span><span class="tok-o">.</span><span class="tok-n">map</span><span class="tok-o">{</span> <span class="tok-nc">JSON</span><span class="tok-o">.</span><span class="tok-n">parseObject</span><span class="tok-o">(</span><span class="tok-k">_</span><span class="tok-o">,</span><span class="tok-n">classOf</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span><span class="tok-o">])}</span>
<span class="tok-k">val</span> <span class="tok-n">keyedStream</span><span class="tok-k">:</span> <span class="tok-kt">KeyedStream</span><span class="tok-o">[(</span><span class="tok-kt">String</span>, <span class="tok-kt">Int</span><span class="tok-o">)</span>, <span class="tok-kt">Tuple</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">startUplogDstream</span><span class="tok-o">.</span><span class="tok-n">map</span><span class="tok-o">(</span><span class="tok-n">startuplog</span><span class="tok-o">=&gt;(</span><span class="tok-n">startuplog</span><span class="tok-o">.</span><span class="tok-n">ch</span><span class="tok-o">,</span><span class="tok-mi">1</span><span class="tok-o">)).</span><span class="tok-n">keyBy</span><span class="tok-o">(</span><span class="tok-mi">0</span><span class="tok-o">)</span>
<span class="tok-c1">//reduce //sum</span>
<span class="tok-n">keyedStream</span><span class="tok-o">.</span><span class="tok-n">reduce</span><span class="tok-o">{</span>  <span class="tok-o">(</span><span class="tok-n">ch1</span><span class="tok-o">,</span><span class="tok-n">ch2</span><span class="tok-o">)</span><span class="tok-k">=&gt;</span>
  <span class="tok-o">(</span><span class="tok-n">ch1</span><span class="tok-o">.</span><span class="tok-n">_1</span><span class="tok-o">,</span><span class="tok-n">ch1</span><span class="tok-o">.</span><span class="tok-n">_2</span><span class="tok-o">+</span><span class="tok-n">ch2</span><span class="tok-o">.</span><span class="tok-n">_2</span><span class="tok-o">)</span>
<span class="tok-o">}</span> <span class="tok-o">.</span><span class="tok-n">print</span><span class="tok-o">().</span><span class="tok-n">setParallelism</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">)</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_6_split_和_select">4.3.6 Split 和 Select</h4>
<div class="paragraph">
<p>Split</p>
</div>
<div class="paragraph">
<p>DataStream → SplitStream：根据某些特征把一个DataStream拆分成两个或者多个DataStream。
Select</p>
</div>
<div class="paragraph">
<p>SplitStream→DataStream：从一个SplitStream中获取一个或者多个DataStream。</p>
</div>
<div class="paragraph">
<p>需求：把appstore和其他的渠道的数据单独拆分出来，做成两个流</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span>     <span class="tok-c1">// 将appstore与其他渠道拆分拆分出来  成为两个独立的流</span>
<span class="tok-k">val</span> <span class="tok-n">splitStream</span><span class="tok-k">:</span> <span class="tok-kt">SplitStream</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">startUplogDstream</span><span class="tok-o">.</span><span class="tok-n">split</span> <span class="tok-o">{</span> <span class="tok-n">startUplog</span> <span class="tok-k">=&gt;</span>
  <span class="tok-k">var</span> <span class="tok-n">flags</span><span class="tok-k">:</span><span class="tok-kt">List</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">]</span> <span class="tok-k">=</span>  <span class="tok-kc">null</span>
  <span class="tok-k">if</span> <span class="tok-o">(</span><span class="tok-s">&quot;appstore&quot;</span> <span class="tok-o">==</span> <span class="tok-n">startUplog</span><span class="tok-o">.</span><span class="tok-n">ch</span><span class="tok-o">)</span> <span class="tok-o">{</span>
    <span class="tok-n">flags</span> <span class="tok-k">=</span> <span class="tok-nc">List</span><span class="tok-o">(</span><span class="tok-n">startUplog</span><span class="tok-o">.</span><span class="tok-n">ch</span><span class="tok-o">)</span>
  <span class="tok-o">}</span> <span class="tok-k">else</span> <span class="tok-o">{</span>
    <span class="tok-n">flags</span> <span class="tok-k">=</span> <span class="tok-nc">List</span><span class="tok-o">(</span><span class="tok-s">&quot;other&quot;</span> <span class="tok-o">)</span>
  <span class="tok-o">}</span>
  <span class="tok-n">flags</span>
<span class="tok-o">}</span>
<span class="tok-k">val</span> <span class="tok-n">appStoreStream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">splitStream</span><span class="tok-o">.</span><span class="tok-n">select</span><span class="tok-o">(</span><span class="tok-s">&quot;appstore&quot;</span><span class="tok-o">)</span>
<span class="tok-n">appStoreStream</span><span class="tok-o">.</span><span class="tok-n">print</span><span class="tok-o">(</span><span class="tok-s">&quot;apple:&quot;</span><span class="tok-o">).</span><span class="tok-n">setParallelism</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">)</span>
<span class="tok-k">val</span> <span class="tok-n">otherStream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">splitStream</span><span class="tok-o">.</span><span class="tok-n">select</span><span class="tok-o">(</span><span class="tok-s">&quot;other&quot;</span><span class="tok-o">)</span>
<span class="tok-n">otherStream</span><span class="tok-o">.</span><span class="tok-n">print</span><span class="tok-o">(</span><span class="tok-s">&quot;other:&quot;</span><span class="tok-o">).</span><span class="tok-n">setParallelism</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">)</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_7_connect和comap">4.3.7 Connect和CoMap</h4>
<div class="paragraph">
<p>DataStream,DataStream → ConnectedStreams：连接两个保持他们类型的数据流，两个数据流被Connect之后，只是被放在了一个同一个流中，内部依然保持各自的数据和形式不发生任何变化，两个流相互独立。
CoMap,CoFlatMap</p>
</div>
<div class="paragraph">
<p>ConnectedStreams → DataStream：作用于ConnectedStreams上，功能与map和flatMap一样，对ConnectedStreams中的每一个Stream分别进行map和flatMap处理。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-c1">//合并以后打印</span>
<span class="tok-k">val</span> <span class="tok-n">connStream</span><span class="tok-k">:</span> <span class="tok-kt">ConnectedStreams</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span>, <span class="tok-kt">StartUpLog</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">appStoreStream</span><span class="tok-o">.</span><span class="tok-n">connect</span><span class="tok-o">(</span><span class="tok-n">otherStream</span><span class="tok-o">)</span>
<span class="tok-k">val</span> <span class="tok-n">allStream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">connStream</span><span class="tok-o">.</span><span class="tok-n">map</span><span class="tok-o">(</span>
  <span class="tok-o">(</span><span class="tok-n">log1</span><span class="tok-k">:</span> <span class="tok-kt">StartUpLog</span><span class="tok-o">)</span> <span class="tok-k">=&gt;</span> <span class="tok-n">log1</span><span class="tok-o">.</span><span class="tok-n">ch</span><span class="tok-o">,</span>
  <span class="tok-o">(</span><span class="tok-n">log2</span><span class="tok-k">:</span> <span class="tok-kt">StartUpLog</span><span class="tok-o">)</span> <span class="tok-k">=&gt;</span> <span class="tok-n">log2</span><span class="tok-o">.</span><span class="tok-n">ch</span>
<span class="tok-o">)</span>
<span class="tok-n">allStream</span><span class="tok-o">.</span><span class="tok-n">print</span><span class="tok-o">(</span><span class="tok-s">&quot;connect::&quot;</span><span class="tok-o">)</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_4_3_8_union">4.3.8 Union</h4>
<div class="paragraph">
<p>DataStream → DataStream：对两个或者两个以上的DataStream进行union操作，产生一个包含所有DataStream元素的新DataStream。注意:如果你将一个DataStream跟它自己做union操作，在新的DataStream中，你将看到每一个元素都出现两次。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-c1">//合并以后打印</span>
<span class="tok-k">val</span> <span class="tok-n">unionStream</span><span class="tok-k">:</span> <span class="tok-kt">DataStream</span><span class="tok-o">[</span><span class="tok-kt">StartUpLog</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-n">appStoreStream</span><span class="tok-o">.</span><span class="tok-n">union</span><span class="tok-o">(</span><span class="tok-n">otherStream</span><span class="tok-o">)</span>
<span class="tok-n">unionStream</span><span class="tok-o">.</span><span class="tok-n">print</span><span class="tok-o">(</span><span class="tok-s">&quot;union:::&quot;</span><span class="tok-o">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Connect与 Union 区别：
1 、 Union之前两个流的类型必须是一样，Connect可以不一样，在之后的coMap中再去调整成为一样的。
2 Connect只能操作两个流，Union可以操作多个</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_4_sink">4.4 Sink</h3>
<div class="literalblock">
<div class="content">
<pre>Flink没有类似于spark中foreach方法，让用户进行迭代的操作。虽有对外的输出操作都要利用Sink完成。最后通过类似如下方式完成整个任务最终输出操作。</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>myDstream.addSink(new MySink(xxxx))</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre>官方提供了一部分的框架的sink。除此以外，需要用户自定义实现sink。</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka-0.11 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>mykafkaUtil中增加方法</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def getProducer(topic:String): FlinkKafkaProducer011[String] ={
  new FlinkKafkaProducer011[String](brokerList,topic,new SimpleStringSchema())
}</pre>
</div>
</div>
<div class="paragraph">
<p>主函数中添加sink</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val myKafkaProducer: FlinkKafkaProducer011[String] = MyKafkaUtil.getProducer("channel_sum")

sumDstream.map( chCount=&gt;chCount._1+":"+chCount._2 ).addSink(myKafkaProducer)</pre>
</div>
</div>
<div class="sect3">
<h4 id="_4_4_1_elasticsearch">4.4.1 Elasticsearch</h4>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-connector-elasticsearch6_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
    &lt;version&gt;4.5.3&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>添加MyEsUtil</p>
</div>
<div class="listingblock">
<div class="content">
<pre>import java.util

import com.alibaba.fastjson.{JSON, JSONObject}
import org.apache.flink.api.common.functions.RuntimeContext
import org.apache.flink.streaming.connectors.elasticsearch.{ElasticsearchSinkFunction, RequestIndexer}
import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink
import org.apache.http.HttpHost
import org.elasticsearch.action.index.IndexRequest
import org.elasticsearch.client.Requests

object MyEsUtil {

  val httpHosts = new util.ArrayList[HttpHost]
  httpHosts.add(new HttpHost("hadoop1",9200,"http"))
   httpHosts.add(new HttpHost("hadoop2",9200,"http"))
   httpHosts.add(new HttpHost("hadoop3",9200,"http"))

  def  getElasticSearchSink(indexName:String):  ElasticsearchSink[String]  ={
    val esFunc = new ElasticsearchSinkFunction[String] {
      override def process(element: String, ctx: RuntimeContext, indexer: RequestIndexer): Unit = {
        println("试图保存："+element)
        val jsonObj: JSONObject = JSON.parseObject(element)
        val indexRequest: IndexRequest = Requests.indexRequest().index(indexName).`type`("_doc").source(jsonObj)
        indexer.add(indexRequest)
        println("保存1条")
      }
    }

    val sinkBuilder = new ElasticsearchSink.Builder[String](httpHosts, esFunc)

    //刷新前缓冲的最大动作量
    sinkBuilder.setBulkFlushMaxActions(10)

    sinkBuilder.build()
  }
}</pre>
</div>
</div>
<div class="paragraph">
<p>在main方法中调用</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="scala"><span></span><span class="tok-c1">// 明细发送到es 中</span>
<span class="tok-k">val</span> <span class="tok-n">esSink</span><span class="tok-k">:</span> <span class="tok-kt">ElasticsearchSink</span><span class="tok-o">[</span><span class="tok-kt">String</span><span class="tok-o">]</span> <span class="tok-k">=</span> <span class="tok-nc">MyEsUtil</span><span class="tok-o">.</span><span class="tok-n">getElasticSearchSink</span><span class="tok-o">(</span><span class="tok-s">&quot;gmall0503_startup&quot;</span><span class="tok-o">)</span>
<span class="tok-n">dstream</span><span class="tok-o">.</span><span class="tok-n">addSink</span><span class="tok-o">(</span><span class="tok-n">esSink</span><span class="tok-o">)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第五章_time与window">第五章 Time与Window</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_5_1_time">5.1 Time</h3>
<div class="paragraph">
<p>在Flink的流式处理中，会涉及到时间的不同概念，如下图所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/event_ingestion_processing_time.svg" alt="event ingestion processing time">
</div>
</div>
<div class="paragraph">
<p><strong>Event Time</strong>：是事件创建的时间。它通常由事件中的时间戳描述，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件时间戳。
<strong>Ingestion Time</strong>：是数据进入Flink的时间。
<strong>Processing Time</strong>：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Time。
例如，一条日志进入Flink的时间为2017-11-12 10:00:00.123，到达Window的系统时间为2017-11-12 10:00:01.234，日志的内容如下:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2017-11-02 18:37:15.624 INFO Fail over to rm2</pre>
</div>
</div>
<div class="paragraph">
<p>对于业务来说，要统计1min内的故障日志个数，哪个时间是最有意义的？—— eventTime，因为我们要根据日志的生成时间进行统计。</p>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_window">5.2 Window</h3>
<div class="sect3">
<h4 id="_5_2_1_window概述">5.2.1 Window概述</h4>
<div class="paragraph">
<p>streaming流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，而window是一种切割无限数据为有限块进行处理的手段。
Window是无限数据流处理的核心，Window将一个无限的stream拆分成有限大小的”buckets”桶，我们可以在这些桶上做计算操作。
==== 5.2.2 Window类型
Window可以分成两类：
CountWindow：按照指定的数据条数生成一个Window，与时间无关。
TimeWindow：按照时间生成Window。
对于TimeWindow，可以根据窗口实现原理的不同分成三类：滚动窗口（Tumbling Window）、滑动窗口（Sliding Window）和会话窗口（Session Window）。
滚动窗口（Tumbling Windows）
将数据依据固定的窗口长度对数据进行切片。
特点：时间对齐，窗口长度固定，没有重叠。
滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，并且不会出现重叠。例如：如果你指定了一个5分钟大小的滚动窗口，窗口的创建如下图所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/tumbling-windows.svg" alt="tumbling windows">
</div>
</div>
<div class="paragraph">
<p>适用场景：适合做BI统计等（做每个时间段的聚合计算）。
滑动窗口（Sliding Windows）
滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成。
特点：时间对齐，窗口长度固定，有重叠。
滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，窗口是可以重叠的，在这种情况下元素会被分配到多个窗口中。
例如，你有10分钟的窗口和5分钟的滑动，那么每个窗口中5分钟的窗口里包含着上个10分钟产生的数据，如下图所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/sliding-windows.svg" alt="sliding windows">
</div>
</div>
<div class="paragraph">
<p>适用场景：对最近一个时间段内的统计（求某接口最近5min的失败率来决定是否要报警）。
会话窗口（Session Windows）
由一系列事件组合一个指定时间长度的timeout间隙组成，类似于web应用的session，也就是一段时间没有接收到新数据就会生成新的窗口。
特点：时间无对齐。
session窗口分配器通过session活动来对元素进行分组，session窗口跟滚动窗口和滑动窗口相比，不会有重叠和固定的开始时间和结束时间的情况，相反，当它在一个固定的时间周期内不再收到元素，即非活动间隔产生，那个这个窗口就会关闭。一个session窗口通过一个session间隔来配置，这个session间隔定义了非活跃周期的长度，当这个非活跃周期产生，那么当前的session将关闭并且后续的元素将被分配到新的session窗口中去。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/session-windows.svg" alt="session windows">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_3_window_api">5.3 Window API</h3>
<div class="paragraph">
<p>TimeWindow
TimeWindow是将指定时间范围内的所有数据组成一个window，一次对一个window里面的所有数据进行计算。
滚动窗口
Flink默认的时间窗口根据Processing Time 进行窗口的划分，将Flink获取到的数据根据进入Flink的时间划分到不同的窗口中。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//每10统计一次各个渠道的计数
val windowedStream: WindowedStream[(String, Int), Tuple, TimeWindow] = keyedStream.timeWindow(Time.seconds(10))
val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
<div class="paragraph">
<p>时间间隔可以通过Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。
滑动窗口（SlidingEventTimeWindows）
滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。
下面代码中的sliding_size设置为了2s，也就是说，窗口每2s就计算一次，每一次计算的window范围是5s内的所有元素。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//每5秒统计一次最近10秒的各个渠道的计数
val windowedStream: WindowedStream[(String, Int), Tuple, TimeWindow] = keyedStream.timeWindow(Time.seconds(10),Time.seconds(5))
val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
<div class="paragraph">
<p>时间间隔可以通过Time.milliseconds(x)，Time.seconds(x)，Time.minutes(x)等其中的一个来指定。</p>
</div>
<div class="paragraph">
<p>CountWindow
CountWindow根据窗口中相同key元素的数量来触发执行，执行时只计算元素数量达到窗口大小的key对应的结果。
注意：CountWindow的window_size指的是相同Key的元素的个数，不是输入的所有元素的总数。
滚动窗口
默认的CountWindow是一个滚动窗口，只需要指定窗口大小即可，当元素数量达到窗口大小时，就会触发窗口的执行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
 //每当某一个key的个数达到10的时候，显示出来
 val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10)
 val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
<div class="paragraph">
<p>滑动窗口
滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。
下面代码中的sliding_size设置为了2，也就是说，每收到两个相同key的数据就计算一次，每一次计算的window范围是5个元素。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val keyedStream: KeyedStream[(String, Int), Tuple] = startUplogDstream.map(startuplog=&gt;(startuplog.ch,1)).keyBy(0)
//每当某一个key的个数达到2的时候,触发计算，计算最近该key最近10个元素的内容
val windowedStream: WindowedStream[(String, Int), Tuple, GlobalWindow] = keyedStream.countWindow(10,2)
val sumDstream: DataStream[(String, Int)] = windowedStream.sum(1)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第六章_eventtime与window">第六章 EventTime与Window</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_6_1_eventtime的引入">6.1 EventTime的引入</h3>
<div class="paragraph">
<p>在Flink的流式处理中，绝大部分的业务都会使用eventTime，一般只在eventTime无法使用时，才会被迫使用ProcessingTime或者IngestionTime。
如果要使用EventTime，那么需要引入EventTime的时间属性，引入方式如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>val env = StreamExecutionEnvironment.getExecutionEnvironment

// 从调用时刻开始给env创建的每一个stream追加时间特征
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_6_2_watermark">6.2 Watermark</h3>
<div class="sect3">
<h4 id="_6_2_1_基本概念">6.2.1 基本概念</h4>
<div class="paragraph">
<p>我们知道，流处理从事件产生，到流经source，再到operator，中间是有一个过程和时间的，虽然大部分情况下，流到operator的数据都是按照事件产生的时间顺序来的，但是也不排除由于网络、分布式等原因，导致乱序的产生，所谓乱序，就是指Flink接收到的事件的先后顺序不是严格按照事件的Event Time顺序排列的。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/stream_watermark_in_order.svg" alt="stream watermark in order">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/stream_watermark_out_of_order.svg" alt="stream watermark out of order">
</div>
</div>
<div class="paragraph">
<p>那么此时出现一个问题，一旦出现乱序，如果只根据eventTime决定window的运行，我们不能明确数据是否全部到位，但又不能无限期的等下去，此时必须要有个机制来保证一个特定的时间后，必须触发window去进行计算了，这个特别的机制，就是Watermark。
Watermark是一种衡量Event Time进展的机制，它是数据本身的一个隐藏属性，数据本身携带着对应的Watermark。
Watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用Watermark机制结合window来实现。
数据流中的Watermark用于表示timestamp小于Watermark的数据，都已经到达了，因此，window的执行也是由Watermark触发的。
Watermark可以理解成一个延迟触发机制，我们可以设置Watermark的延时时长t，每次系统会校验已经到达的数据中最大的maxEventTime，然后认定eventTime小于maxEventTime - t的所有数据都已经到达，如果有窗口的停止时间等于maxEventTime – t，那么这个窗口被触发执行。
有序流的Watermarker如下图所示：（Watermark设置为0）
乱序流的Watermarker如下图所示：（Watermark设置为2）
当Flink接收到每一条数据时，都会产生一条Watermark，这条Watermark就等于当前所有到达数据中的maxEventTime - 延迟时长，也就是说，Watermark是由数据携带的，一旦数据携带的Watermark比当前未触发的窗口的停止时间要晚，那么就会触发相应窗口的执行。由于Watermark是由数据携带的，因此，如果运行过程中无法获取新的数据，那么没有被触发的窗口将永远都不被触发。
上图中，我们设置的允许最大延迟到达时间为2s，所以时间戳为7s的事件对应的Watermark是5s，时间戳为12s的事件的Watermark是10s，如果我们的窗口1是1s<sub>5s，窗口2是6s</sub>10s，那么时间戳为7s的事件到达时的Watermarker恰好触发窗口1，时间戳为12s的事件到达时的Watermark恰好触发窗口2。</p>
</div>
<div class="paragraph">
<p>Watermark 就是触发前一窗口的“关窗时间”，一旦触发关门那么以当前时刻为准在窗口范围内的所有所有数据都会收入窗中。
只要没有达到水位那么不管现实中的时间推进了多久都不会触发关窗。</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_2_2_watermark的引入">6.2.2 Watermark的引入</h4>
<div class="listingblock">
<div class="content">
<pre>val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
  override def extractTimestamp(element: (String, Long, Int)): Long = {

   return  element._2
  }
})</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_6_3_evnettimewindow_api">6.3 EvnetTimeWindow API</h3>
<div class="sect3">
<h4 id="_6_3_1_滚动窗口tumblingeventtimewindows">6.3.1 滚动窗口（TumblingEventTimeWindows）</h4>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
    //  环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val dstream: DataStream[String] = env.socketTextStream("hadoop1",7777)



    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map { text =&gt;
      val arr: Array[String] = text.split(" ")
      (arr(0), arr(1).toLong, 1)
    }
    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
      override def extractTimestamp(element: (String, Long, Int)): Long = {

       return  element._2
      }
    })

    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)
    textKeyStream.print("textkey:")

    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(TumblingEventTimeWindows.of(Time.seconds(2)))

    val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream.fold(new mutable.HashSet[Long]()) { case (set, (key, ts, count)) =&gt;
      set += ts
    }

    groupDstream.print("window::::").setParallelism(1)

    env.execute()

  }

}</pre>
</div>
</div>
<div class="paragraph">
<p>结果是按照Event Time的时间窗口计算得出的，而无关系统的时间（包括输入的快慢）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_2_滑动窗口slidingeventtimewindows">6.3.2 滑动窗口（SlidingEventTimeWindows）</h4>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
  //  环境
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
  env.setParallelism(1)

  val dstream: DataStream[String] = env.socketTextStream("hadoop1",7777)



  val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map { text =&gt;
    val arr: Array[String] = text.split(" ")
    (arr(0), arr(1).toLong, 1)
  }
  val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
    override def extractTimestamp(element: (String, Long, Int)): Long = {

     return  element._2
    }
  })

  val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)
  textKeyStream.print("textkey:")

  val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(SlidingEventTimeWindows.of(Time.seconds(2),Time.milliseconds(500)))

  val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream.fold(new mutable.HashSet[Long]()) { case (set, (key, ts, count)) =&gt;
    set += ts
  }

  groupDstream.print("window::::").setParallelism(1)

  env.execute()

}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_6_3_3_会话窗口eventtimesessionwindows">6.3.3 会话窗口（EventTimeSessionWindows）</h4>
<div class="paragraph">
<p>相邻两次数据的EventTime的时间差超过指定的时间间隔就会触发执行。如果加入Watermark， 会在符合窗口触发的情况下进行延迟。到达延迟水位再进行窗口触发。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
    //  环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val dstream: DataStream[String] = env.socketTextStream("hadoop1",7777)

    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream.map { text =&gt;
      val arr: Array[String] = text.split(" ")
      (arr(0), arr(1).toLong, 1)
    }
    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
      override def extractTimestamp(element: (String, Long, Int)): Long = {

       return  element._2
      }
    })

    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream.keyBy(0)
    textKeyStream.print("textkey:")

    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream.window(EventTimeSessionWindows.withGap(Time.milliseconds(500)) )

    windowStream.reduce((text1,text2)=&gt;
      (  text1._1,0L,text1._3+text2._3)
    )  .map(_._3).print("windows:::").setParallelism(1)

    env.execute()

  }</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第七章_table_api_与sql">第七章 Table API 与SQL</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Table API是流处理和批处理通用的关系型API，Table API可以基于流输入或者批输入来运行而不需要进行任何修改。Table API是SQL语言的超集并专门为Apache Flink设计的，Table API是Scala 和Java语言集成式的API。与常规SQL语言中将查询指定为字符串不同，Table API查询是以Java或Scala中的语言嵌入样式来定义的，具有IDE支持如:自动完成和语法检测。</p>
</div>
<div class="sect2">
<h3 id="_7_1_需要引入的pom依赖">7.1 需要引入的pom依赖</h3>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-table_2.11&lt;/artifactId&gt;
    &lt;version&gt;1.7.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_7_2_构造表环境">7.2 构造表环境</h3>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer("GMALL_STARTUP")
  val dstream: DataStream[String] = env.addSource(myKafkaConsumer)

  val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env)

  val startupLogDstream: DataStream[StartupLog] = dstream.map{ jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) }

  val startupLogTable: Table = tableEnv.fromDataStream(startupLogDstream)

   val table: Table = startupLogTable.select("mid,ch").filter("ch ='appstore'")

  val midchDataStream: DataStream[(String, String)] = table.toAppendStream[(String,String)]

  midchDataStream.print()
  env.execute()
}</pre>
</div>
</div>
<div class="paragraph">
<p>动态表</p>
</div>
<div class="paragraph">
<p>如果流中的数据类型是case class可以直接根据case class的结构生成table
tableEnv.fromDataStream(startupLogDstream)
或者根据字段顺序单独命名
tableEnv.fromDataStream(startupLogDstream,’mid,’uid  &#8230;&#8203;&#8230;&#8203;.)</p>
</div>
<div class="paragraph">
<p>最后的动态表可以转换为流进行输出
table.toAppendStream[(String,String)]</p>
</div>
<div class="paragraph">
<p>字段
 用一个单引放到字段前面 来标识字段名, 如 ‘name , ‘mid ,’amount 等</p>
</div>
</div>
<div class="sect2">
<h3 id="_7_3_通过一个例子_了解tableapi">7.3 通过一个例子 了解TableAPI</h3>
<div class="listingblock">
<div class="content">
<pre>//每10秒中渠道为appstore的个数
def main(args: Array[String]): Unit = {
  //sparkcontext
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  //时间特性改为eventTime
  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

  val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer("GMALL_STARTUP")
  val dstream: DataStream[String] = env.addSource(myKafkaConsumer)

  val startupLogDstream: DataStream[StartupLog] = dstream.map{ jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) }
  //告知watermark 和 eventTime如何提取
  val startupLogWithEventTimeDStream: DataStream[StartupLog] = startupLogDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[StartupLog](Time.seconds(0L)) {
    override def extractTimestamp(element: StartupLog): Long = {
      element.ts
    }
  }).setParallelism(1)

  //SparkSession
  val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env)

  //把数据流转化成Table
  val startupTable: Table = tableEnv.fromDataStream(startupLogWithEventTimeDStream , 'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime)

  //通过table api 进行操作
  // 每10秒 统计一次各个渠道的个数 table api 解决
  //1 groupby  2 要用 window   3 用eventtime来确定开窗时间
  val resultTable: Table = startupTable.window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch,'tt ).select( 'ch, 'ch.count)



  //把Table转化成数据流
  //val appstoreDStream: DataStream[(String, String, Long)] = appstoreTable.toAppendStream[(String,String,Long)]
  val resultDstream: DataStream[(Boolean, (String, Long))] = resultSQLTable.toRetractStream[(String,Long)]

  resultDstream.filter(_._1).print()

  env.execute()

}</pre>
</div>
</div>
<div class="paragraph">
<p>关于group by
如果使用 groupby table转换为流的时候只能用toRetractDstream
  val rDstream: DataStream[(Boolean, (String, Long))] = table.toRetractStream[(String,Long)]</p>
</div>
<div class="paragraph">
<p>toRetractDstream 得到的第一个boolean型字段标识 true就是最新的数据，false表示过期老数据</p>
</div>
<div class="literalblock">
<div class="content">
<pre>val rDstream: DataStream[(Boolean, (String, Long))] = table.toRetractStream[(String,Long)]
rDstream.filter(_._1).print()</pre>
</div>
</div>
<div class="paragraph">
<p>如果使用的api包括时间窗口，那么时间的字段必须，包含在group by中。
  val table: Table = startupLogTable.filter("ch ='appstore'").window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch ,'tt).select("ch,ch.count ")</p>
</div>
<div class="paragraph">
<p>关于时间窗口
用到时间窗口，必须提前声明时间字段，如果是processTime直接在创建动态表时进行追加就可以</p>
</div>
<div class="paragraph">
<p>val startupLogTable: Table = tableEnv.fromDataStream(startupLogWithEtDstream,'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime)</p>
</div>
<div class="paragraph">
<p>如果是EventTime要在创建动态表时声明
val startupLogTable: Table = tableEnv.fromDataStream(startupLogWithEtDstream,'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ps.processtime)</p>
</div>
<div class="paragraph">
<p>滚动窗口可以使用Tumble over 10000.millis on
  val table: Table = startupLogTable.filter("ch ='appstore'").window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch ,'tt).select("ch,ch.count ")</p>
</div>
</div>
<div class="sect2">
<h3 id="_7_4_sql如何编写">7.4 SQL如何编写</h3>
<div class="listingblock">
<div class="content">
<pre>def main(args: Array[String]): Unit = {
  //sparkcontext
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  //时间特性改为eventTime
  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

  val myKafkaConsumer: FlinkKafkaConsumer011[String] = MyKafkaUtil.getConsumer("GMALL_STARTUP")
  val dstream: DataStream[String] = env.addSource(myKafkaConsumer)

  val startupLogDstream: DataStream[StartupLog] = dstream.map{ jsonString =&gt;JSON.parseObject(jsonString,classOf[StartupLog]) }
  //告知watermark 和 eventTime如何提取
  val startupLogWithEventTimeDStream: DataStream[StartupLog] = startupLogDstream.assignTimestampsAndWatermarks(new BoundedOutOfOrdernessTimestampExtractor[StartupLog](Time.seconds(0L)) {
    override def extractTimestamp(element: StartupLog): Long = {
      element.ts
    }
  }).setParallelism(1)

  //SparkSession
  val tableEnv: StreamTableEnvironment = TableEnvironment.getTableEnvironment(env)

  //把数据流转化成Table
  val startupTable: Table = tableEnv.fromDataStream(startupLogWithEventTimeDStream , 'mid,'uid,'appid,'area,'os,'ch,'logType,'vs,'logDate,'logHour,'logHourMinute,'ts.rowtime)

  //通过table api 进行操作
  // 每10秒 统计一次各个渠道的个数 table api 解决
  //1 groupby  2 要用 window   3 用eventtime来确定开窗时间
  val resultTable: Table = startupTable.window(Tumble over 10000.millis on 'ts as 'tt).groupBy('ch,'tt ).select( 'ch, 'ch.count)
 // 通过sql 进行操作

  val resultSQLTable : Table = tableEnv.sqlQuery( "select ch ,count(ch)   from "+startupTable+"  group by ch   ,Tumble(ts,interval '10' SECOND )")

  //把Table转化成数据流
  //val appstoreDStream: DataStream[(String, String, Long)] = appstoreTable.toAppendStream[(String,String,Long)]
  val resultDstream: DataStream[(Boolean, (String, Long))] = resultSQLTable.toRetractStream[(String,Long)]

  resultDstream.filter(_._1).print()

  env.execute()

}</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_第八章_dataflow模型">第八章 Dataflow模型</h2>
<div class="sectionbody">
<div class="paragraph">
<p>一种能平衡准确性，延迟程度，处理成本的大规模无边界乱序数据处理实践方法</p>
</div>
<div class="sect2">
<h3 id="_8_0_摘要">8.0 摘要</h3>
<div class="paragraph">
<p>在日常商业运营中，无边界、乱序、大规模数据集越来越普遍了。(例如，网站日志，手机应用统计，传感器网络)。同时，对这些数据的消费需求也越来越复杂。比如说按事件发生时间序列处理数据，按数据本身的特征进行窗口计算等等。同时人们也越来越苛求立刻得到数据分析结果。然而，实践表明，我们永远无法同时优化数据处理的准确性、延迟程度和处理成本等各个维度。因此，数据工作者面临如何协调这些几乎相互冲突的数据处理技术指标的窘境，设计出来各种纷繁的数据处理系统和实践方法。</p>
</div>
<div class="paragraph">
<p>我们建议数据处理的方法必须进行根本性的改进。作为数据工作者，我们不能把无边界数据集(数据流)切分成有边界的数据，等待一个批次完整后处理。相反地，我们应该假设我们永远无法知道数据流是否终结，何时数据会变完整。唯一应该确信的是，新的数据会源源不断而来，老的数据可能会被撤销或更新。而能够让数据工作者应对这个挑战的唯一可行的方法是通过一个遵守原则的抽象来平衡折衷取舍数据处理的准确性、延迟程度和处理成本。在这篇论文中，我们提出了Dataflow模型，并详细地阐述了它的语义，设计的核心原则，以及在实践开发过程中对模型的检验。</p>
</div>
</div>
<div class="sect2">
<h3 id="_8_1_简介">8.1 简介</h3>
<div class="paragraph">
<p>现代数据处理是一个复杂而又令人兴奋的领域。MapReduce和它的衍生系统(如Hadoop, Pig, Hive, Spark等)解决了处理数据的"量"上的问题。流处理SQL上社区也做了很多的工作(如查询系统，窗口，数据流，时间维度，语义模型)。在低延时处理上Spark Streaming, MillWheel, Storm等做了很多尝试。数据工作者现在拥有了很多强有力的工具把大规模无序的数据加工成结构化的数据，而结构化的数据拥有远大于原始数据的价值。但是我们仍然认为现存的模型和方法在处理一些常见的场景时有心无力。</p>
</div>
<div class="paragraph">
<p>考虑一个例子：一家流媒体平台提供商通过视频广告，向广告商收费把视频内容进行商业变现。收费标准按广告收看次数、时长来计费。这家流媒体的平台支持在线和离线播放。流媒体平台提供商希望知道每天向广告商收费的金额，希望按视频和广告进行汇总统计。另外，他们想在大量的历史离线数据上进行历史数据分析，进行各种实验。</p>
</div>
<div class="paragraph">
<p>广告商和内容提供者想知道视频被观看了多少次，观看了多长时间，视频被播放时投放了哪个广告，或者广告播放是投放在哪个视频内容中，观看的人群统计分布是什么。广告商也很想知道需要付多少钱，而内容提供者想知道赚到了多少钱。而他们需要尽快得到这些信息，以便调整预算/调整报价，改变受众，修正促销方案，调整未来方向。所有这些越实时越好，因涉及到金额，准确性是至关重要的。</p>
</div>
<div class="paragraph">
<p>尽管数据处理系统天生就是复杂的，视频平台还是希望一个简单而灵活的编程模型。最后，由于他们基于互联网的业务遍布全球，他们需要的系统要能够处理分散在全球的数据。</p>
</div>
<div class="paragraph">
<p>上述场景需要计算的指标包括每个视频观看的时间和时长，观看者、视频内容和广告是如何组合的(即按用户，按视频的观看"会话")。概念上这些指标都非常直观，但是现有的模型和系统并无法完美地满足上述的技术要求。</p>
</div>
<div class="paragraph">
<p>批处理系统如MapReduce(包括Hadoop的变种，如Pig，Hive)，FlumeJava, Spark等无法满足时延的要求，因为批处理系统需要等待收集所有的数据成一个批次后才开始处理。对有些流处理系统来说，目前不了解它们在大规模使用的情况下是否还能保持容错性(如(Aurora, TelegraphCQ, Niagara, Esper)，而那些提供了可扩展性和容错性的系统则缺乏准确性或语义的表达性。很多系统缺乏“恰好处理一次”的语义(如Storm, Samza, Pulsar)影响了数据的准确性。或者提供了窗口但语义局限于基于记录数或基于数据处理时间的窗口(Spark Streamming, Sonora, Trident)。而大多数提供了基于事件发生时间窗口的，或者依赖于消息必须有序(SQLStream)或者缺乏按事件发生时间触发窗口计算的语义(Stratosphere/Flink)。CEDR和Trill可能值得一提，它们不仅提供了有用的标记触发语义，而且提供了一种增量模型，这一点上和我们这篇论文一致，但它们的窗口语义无法有效地表达基于会话的窗口。它们基于标记的触发语义也无法有效处理3.3节中的某些场景。MillWheel和Spark Streaming的可扩展性良好，容错性不错，低延时，是一种合理的方案，但是对于会话窗口缺乏一种直观的高层编程模型。我们发现只有Pulsar系统对非对齐窗口(译者注：指只有部分记录进入某一特定窗口，会话窗口就是一种非对齐窗口)提供了高层次语义抽象，但是它缺乏对数据准确性的保证。Lambda架构能够达到上述的大部分要求，但是系统体系太过复杂，必须构建和维护两套系统(译者注：指离线和在线系统)。Summingbird改善了Lambda体系的复杂性，提供了针对批处理和流处理系统的一个统一封装抽象，但是这种抽象限制了能支持的计算的种类，并且仍然需要维护两套系统，运维复杂性仍然存在。</p>
</div>
<div class="paragraph">
<p>上述的问题并非无药可救，这些系统在活跃的发展中终究会解决这些问题。但是我们认为所有这些模型和系统(除了CEDR和Trill)存在一个比较大的问题。这个问题是他们假设输入数据(不管是无边界或者有边界的)在某个时间点后会变完整。我们认为这种假设是有根本性的问题。我们面临的一方面是庞大无序的数据，另一方面是数据消费者复杂的语义和时间线上的各种需求。对于当下如此多样化和多变的数据使用用例(更别说那些浮现在地平线上的, 译者注：应该是指新的，AI时代的到来带来的对数据使用的新玩法)，我们认为任何一种有广泛实用价值的方法必须提供简单，强有力的工具，可以为手上某个具体的使用案例平衡数据的准确性、延迟程度和处理成本(译者注：意指对某些用例可能需要低延迟更多，某些用例需要准确性更多。而一个好的工具需要能够动态根据用户的使用场景、配置进行适应，具体的技术细节由工具本身消化)。最后，我们认为需要摆脱目前一个主流的观点，认为执行引擎负责描述系统的语义。合理设计和构建的批，微批次，流处理系统能够保证同样程度的准确性。而这三种系统在处理无边界数据流时都非常常见。如果我们抽象出一个具有足够普遍性，灵活性的模型，那么执行引擎的选择就只是延迟程度和处理成本之间的选择。</p>
</div>
<div class="paragraph">
<p>从这个方面来说，这篇论文的概念性贡献在于提出了一个统一的模型能够</p>
</div>
<div class="ulist">
<ul>
<li>
<p>对无边界，无序的数据源，允许按数据本身的特征进行窗口计算，得到基于事件发生时间的有序结果，并能在准确性、延迟程度和处理成本之间调整。</p>
</li>
<li>
<p>解构数据处理管道的四个相关维度，使得它们透明地，灵活地进行组合。</p>
<div class="ulist">
<ul>
<li>
<p>计算什么结果</p>
</li>
<li>
<p>按事件发生时间计算</p>
</li>
<li>
<p>在流计算处理时间时被真正触发计算</p>
</li>
<li>
<p>早期的计算结果如何在后期被修正</p>
</li>
</ul>
</div>
</li>
<li>
<p>分离数据处理的计算逻辑表示和对逻辑的物理实现，使得对批处理，微批处理，流计算引擎的选择成为简单的对准确性、延迟程度和处理成本之间的选择。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>具体来说，上述的贡献包含：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>一个支持非对齐事件发生时间窗口的模型，一组简单的窗口创建和使用的API。（参考2.2）</p>
</li>
<li>
<p>一个根据数据处理管道特征来决定计算结果输出次数的触发模型。一组强有力而灵活的描述触发语义的声明式API。</p>
</li>
<li>
<p>能把数据的更新和撤回和上述窗口、触发模型集成的增量处理模型。（2.3）</p>
</li>
<li>
<p>基于MillWheel流处理引擎和FlumeJava批处理引擎的可扩展实现。为Google Cloud Dataflow重写了外部实现，并提供了一个开源的运行引擎不特定的SDK。（3.1）</p>
</li>
<li>
<p>指导模型设计的一组核心设计原则。</p>
</li>
<li>
<p>Google在处理大规模无边界乱序数据流的处理经验，这也是驱动我们开发这套模型的原因。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>最后，不足为奇地，这个模型没有任何魔术效果。那些现有的强一致性批处理系统，微批处理系统，流处理系统，Lambda系统所无法计算的东西仍然无法解决。CPU, RAM, Disk的内在约束依然存在。我们所提供的是一个能够简单地定义表达并行计算的通用框架。这种表达的方式和底层的执行引擎无关，同时针对任何特定的问题域，提供了根据手上数据和资源的情况来精确地调整延时程度和准确性的能力。从这一点上来说，这个模型的目标是简化大规模数据处理管道的构建。</p>
</div>
<div class="sect3">
<h4 id="_8_1_1_无边界有边界与流处理批处理">8.1.1   无边界、有边界与流处理、批处理</h4>
<div class="paragraph">
<p>(本论文中)当描述无限/有限数据集时，我们更愿意使用有边界/无边界这组词汇，而不是流/批。因为流/批可能意味着使用某种特定的执行引擎。在现实中，无边界数据集可以用批处理系统反复调度来处理，而良好设计的流处理系统也可以完美地处理有边界数据集。从这个模型的角度来看，区分流/批的意义是不大的，因此我们保留这组词汇(流、批)用来专指执行引擎。</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_1_2_窗口">8.1.2 窗口</h4>
<div class="paragraph">
<p>窗口操作把一个数据集切分为有限的数据片以便于聚合处理。当面对无边界的数据时，有些操作需要窗口(以定义大多数聚合操作需要的边界：汇总，外链接，以时间区域定义的操作；如最近5分钟xx等)。另一些则不需要(如过滤，映射，内链接等)。对有边界的数据，窗口是可选的，不过很多情况下仍然是一种有效的语义概念(如回填一大批的更新数据到之前读取无边界数据源处理过的数据, 译者注：类似于Lambda架构)。窗口基本上都是基于时间的；不过也有些系统支持基于记录数的窗口。这种窗口可以认为是基于一个逻辑上的时间域，该时间域中的元素包含顺序递增的逻辑时间戳。窗口可以是对齐的，也就是说窗口应用于所有落在窗口时间范围内的数据。也可以是非对齐的，也就是应用于部分特定的数据子集(如按某个键值筛选的数据子集)。图一列出了处理无边界数据时常见的三种窗口。</p>
</div>
<div class="paragraph">
<p>固定窗口(有时叫翻滚窗口)是按固定窗口大小定义的，比如说小时窗口或天窗口。它们一般是对齐窗口，也就是说，每个窗口都包含了对应时间段范围内的所有数据。有时为了把窗口计算的负荷均匀分摊到整个时间范围内，有时固定窗口会做成把窗口的边界的时间加上一个随机数，这样的固定窗口则变成了不对齐窗口。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/windowpattern.png" alt="windowpattern">
</div>
</div>
<div class="paragraph">
<p>滑动窗口按窗口大小和滑动周期大小来定义，比如说小时窗口，每一分钟滑动一次。这个滑动周期一般比窗口大小小，也就是说窗口有相互重合之处。滑动窗口一般也是对齐的；尽管上面的图为了画出滑动的效果窗口没有遮盖到所有的键，但其实五个滑动窗口其实是包含了所有的3个键，而不仅仅是窗口3包含了所有的3个键。固定窗口可以看做是滑动窗口的一个特例，即窗口大小和滑动周期大小相等。</p>
</div>
<div class="paragraph">
<p>会话是在数据的子集上捕捉一段时间内的活动。一般来说会话按超时时间来定义，任何发生在超时时间以内的事件认为属于同一个会话。会话是非对齐窗口。如上图，窗口2只包含key 1，窗口3则只包含key 2。而窗口1和4都包含了key 3。(译者注：假设key是用户id，那么两次活动之间间隔超过了超时时间，因此系统需要重新定义一个会话窗口。)</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_1_3_时间域">8.1.3 时间域</h4>
<div class="paragraph">
<p>当处理包含事件发生时间的数据时，有两个时间域需要考虑。尽管已经有很多文献提到(特别是时间管理，语义模型，窗口，乱序处理，标记，心跳，水位标记，帧)，这里仍然重复一下，因为这个概念清晰之后2.3节会更易于理解。这两个时间域是：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>事件发生时间。事件发生时间是指当该事件发生时，该事件所在的系统记录下来的系统时间。</p>
</li>
<li>
<p>处理时间。处理时间是指在数据处理管道中处理数据时，一个事件被数据处理系统观察到的时间，是数据处理系统的时间。注意我们这里不假设在分布式系统中时钟是同步的。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>一个事件的事件发生时间是永远不变的，但是一个事件的处理时间随着它在数据管道中一步步被处理时持续变化的。这个区别是非常重要的，特别是我们需要根据事件的发生时间进行分析的时候。</p>
</div>
<div class="paragraph">
<p>在数据处理过程中，由于系统本身的一些现实影响(通信延迟，调度算法，处理时长，管道中间数据序列化等)会导致这两个时间存在差值且动态波动(见图2)。使用记录全局数据处理进度的标记、或水位标记，是一种很好的方式来可视化这个差值。在本论文中，我们采用一种类似MillWheel的水位标记，它是一个时间戳，代表小于这个时间戳的数据已经完全被系统处理了(通常用启发式方法建立)。我们之前曾经说过，数据已经被完全处理的标记经常和数据的准确性是相互冲突的，因此，我们不会太过于依赖于水位标记。不过，它确实是一种有用的手段。系统可以用它猜测所有事件发生时间早于水位标记的数据已经完全被观察到。应用可以用它来可视化处理时间差，也用它来监控系统总体的健康状况和总体处理进展，也可以用它来做一些不影响数据准确性的决策，比如基本垃圾回收策略等。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/timedomainskew.png" alt="timedomainskew">
</div>
</div>
<div class="paragraph">
<p>(译者注：假设事件发生系统和数据处理系统的时钟完全同步)在理想的情况下，两个时间的差值应该永远为零；事件一旦发生，我们就马上处理掉。现实则更像图2那样。从12点开始，由于数据处理管道的延迟，水位标记开始偏离真实时间，12:02时则靠近回来，而12:03的时候延迟变得更大。在分布式数据处理系统里，这种偏差波动非常普遍，在考虑数据处理系统如何提供一个正确的，可重复的结果时，把这种情况纳入考虑很关键。</p>
</div>
<div class="paragraph">
<p>水位标记的建立</p>
</div>
<div class="paragraph">
<p>对大多数现实世界中分布式数据集，系统缺乏足够的信息来建立一个100%准确的水位标记。举例来说，在视频观看"会话"的例子中，考虑离线观看。如果有人把他们的移动设备带到野外，系统根本没有办法知道他们何时会回到有网络连接的地带，然后开始上传他们在没有网络连接时观看视频的数据。因此，大多数的水位定义是基于有限的信息启发式地定义。对于带有未处理数据的元数据的结构化输入源，比如说日志文件(译者注：可能应该不是泛指一般的日志文件)，水位标记的猜测明显要准确些，因此大多数情况下可以作为一个处理完成的估计。另外，很重要的一点，一旦水位标记建立之后，它可以被传递到数据处理管道的下游(就像标记(Punctuation)那样, 译者注：类似于Flink的checkpoint barrier)。当然下游要明确知道这个水位标记仍然是一个猜测。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_8_2_dataflow模型">8.2 DataFlow模型</h3>
<div class="paragraph">
<p>在这一个小节中，我们将定义正式的系统模型。我们还会解释为什么它的语义足够泛化，能涵盖标准的批处理，微批次处理，流处理，以及混合了流批语义的Lambda架构。代码示例是基于Dataflow的Java SDK的一个简化版本，是从FlumeJava API演化而来。</p>
</div>
<div class="sect3">
<h4 id="_8_2_1_核心编程模型">8.2.1 核心编程模型</h4>
<div class="paragraph">
<p>我们先从经典的批处理模型开始来考虑我们的核心编程模型。Dataflow SDK把所有的数据抽象为键值对，对键值对有两个核心的数据转换操作：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>ParDo 用来进行通用的并行化处理。每个输入元素(这个元素本身有可能是一个有限的集合)都会使用一个UDF进行处理(在Dataflow中叫做DoFn)，输出是0或多个输出元素。这个例子是把键的前缀进行展开，然后把值复制到展开后的键构成新的键值对并输出。</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/pardo.png" alt="pardo">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>GroupByKey用来按键值把元素重新分组</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/groupbykey.png" alt="groupbykey">
</div>
</div>
<div class="paragraph">
<p>ParDo操作因为是对每个输入的元素进行处理，因此很自然地就可以适用于无边界的数据。而GroupByKey操作，在把数据发送到下游进行汇总前，需要收集到指定的键对应的所有数据。如果输入源是无边界的，那么我们不知道何时才能收集到所有的数据。所以通常的解决方案是对数据使用窗口操作。</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_2_2_窗口">8.2.2 窗口</h4>
<div class="paragraph">
<p>支持聚合操作的系统经常把GroupByKey操作重新定义成为GroupByKeyAndWindow操作。我们在这一点上的主要贡献是支持非对齐窗口。这个贡献包含两个关键性的洞见：第一是从模型简化的角度上，把所有的窗口策略都当做非对齐窗口，而底层实现来负责把对齐窗口作为一个特例进行优化。第二点是窗口操作可以被分隔为两个互相相关的操作：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>set&lt;Window&gt; AssignWindows(T datum)即窗口分配操作。这个操作把元素分配到0或多个窗口中去。这个也就是Li在[22]中提到的桶操作符。</p>
</li>
<li>
<p>set&lt;window&gt; MergeWindows(Set&lt;Window&gt;  windows)即窗口合并操作，这个操作在汇总时合并窗口。这使得数据驱动的窗口在随着数据到达的过程中逐渐建立起来并进行汇总操作。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>对于任何一种窗口策略，这两种操作都是密切相关的。滑动窗口分配需要滑动窗口合并，而会话窗口分配需要会话窗口合并。</p>
</div>
<div class="paragraph">
<p>注意，为了原生地支持事件发生时间窗口，我们现在定义系统中传递的数据不再仅仅是键值对(key, value)，而是一个四元组(key, value, event_time, window)。数据进入系统时需要自带事件发生时间戳(后期在管道处理过程中也可以修改)，然后初始化分配一个默认的覆盖所有事件发生时间的全局窗口。而全局窗口语义默认等同于标准的批处理模型。</p>
</div>
<div class="sect4">
<h5 id="_8_2_2_1_窗口分配">8.2.2.1 窗口分配</h5>
<div class="paragraph">
<p>从模型角度来说，把一条数据分配给某几个窗口意味着把这条数据复制给了这些窗口。以图3为例，它是把两条记录分配给一个2分钟宽，每一分钟滑动一次的窗口。(简单起见，时间戳用HH:MM的格式给出)</p>
</div>
<div class="paragraph">
<p>在这个例子中，两条数据在两个窗口中冗余存在，因而最后变成了四条记录。另外注意一点，窗口是直接关联到数据元素本身的，因此，窗口的分配可以在处理管道的聚合发生前的任何一处进行。这一点很重要，因为聚合操作有可能是下游复杂组合数据转换的一个子操作。(如Sum.integersPerKey, 译者注：下文会提到，这个转换是指键值对中的值为整形，把整形值按键进行求和)。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/windowassignment.png" alt="windowassignment">
</div>
</div>
</div>
<div class="sect4">
<h5 id="_8_2_2_2_窗口合并">8.2.2.2 窗口合并</h5>
<div class="paragraph">
<p>窗口合并作为GroupByKeyAndWindow的一部分出现，要解释清楚的话，我们最好拿例子来阐述。我们拿会话窗口来作为例子，因为会话窗口正是我们想要解决的用例之一。图4展示了例子数据4条，3条包含的键是k1，一条是k2，窗口按会话窗口组织，会话的过期时间是30分钟。所有4条记录初始时都属于默认的全局窗口。AssignWindows的会话窗口实现把每个元素都放入一个30分钟长的单个窗口，这个窗口的时间段如果和另外一个窗口的时间段相互重合，则意味着这两个窗口应该属于同一个会话。AssignWindows后是GroupByKeyAndWindow的操作，这个操作其实由五个部分组成：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>DropTimestamps – 删除数据上的时间戳，因为窗口合并后，后续的计算只关心窗口。</p>
</li>
<li>
<p>GroupByKey – 把(值, 窗口)二元组按键进行分组</p>
</li>
<li>
<p>MergeWindows – 窗口合并。把同一个键的(值, 窗口)进行窗口合并。具体的合并方式取决于窗口策略。在这个例子中，窗口v1和v4重叠，因此会话窗口策略把这两个窗口合并为一个新的，更长的会话窗口。(如粗体所示)</p>
</li>
<li>
<p>GroupAlsoByWindow – 对每个键，把值按合并后的窗口进行进一步分组。在本例中，由于v1和v4已经合并进了同一个窗口，因此这一步里面v1和v4被分到了同一组。</p>
</li>
<li>
<p>ExpandToElements – 把已经按键，按窗口分好组的元素扩展成(键, 值, 事件发生时间, 窗口)四元组。这里的时间戳是新的按窗口的时间戳。在这个例子里我们取窗口的结束时间作为这条记录的时间戳，但任何大于或等于窗口中最老的那条记录的时间戳都认为是符合水位标记正确性的。</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/windowmerging.png" alt="windowmerging">
</div>
</div>
</div>
<div class="sect4">
<h5 id="_8_2_2_3_api">8.2.2.3 API</h5>
<div class="paragraph">
<p>下面我们使用Cloud Dataflow SDK来展示使用窗口操作的例子。</p>
</div>
<div class="paragraph">
<p>下面是计算对同一个键的整型数值求和</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">input</span> <span class="tok-o">=</span> <span class="tok-n">IO</span><span class="tok-o">.</span><span class="tok-na">read</span><span class="tok-o">(...);</span>
<span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span><span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>假如说要对30分钟长的会话窗口进行同样的计算，那么只要在求和前增加一个window.into调用就可以了</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">input</span> <span class="tok-o">=</span> <span class="tok-n">IO</span><span class="tok-o">.</span><span class="tok-na">read</span><span class="tok-o">(...);</span>
<span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
  <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">into</span><span class="tok-o">(</span><span class="tok-n">Sessions</span><span class="tok-o">.</span><span class="tok-na">withGapDuration</span><span class="tok-o">(</span> <span class="tok-n">Duration</span><span class="tok-o">.</span><span class="tok-na">standardMinutes</span><span class="tok-o">(</span><span class="tok-mi">30</span><span class="tok-o">))))</span>
  <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_8_2_3_触发器和增量处理">8.2.3 触发器和增量处理</h4>
<div class="paragraph">
<p>构建非对齐的事件发生时间窗口是一个进步，不过我们还有两个问题需要解决</p>
</div>
<div class="ulist">
<ul>
<li>
<p>我们需要提供基于记录和基于处理时间的窗口。否则我们会和现有的其他系统的窗口语义不兼容。</p>
</li>
<li>
<p>我们需要知道何时把窗口计算结果发往下游。由于数据事件发生时间的无序性，我们需要某种其他的信号机制来明确窗口已经完结(译者注：就是说，窗口所应该包含的数据已经完全到达并且被窗口观察到，包含到)。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>关于第一点，基于记录数和基于处理时间的窗口，我们会在2.4里解决。而眼下需要讨论建立一个保证窗口完整性的方法。提到窗口完整性，一个最开始的想法是使用某种全局事件发生时间进展机制，比如水位标记来解决。然而，水位标记本身对数据处理的准确性有两个主要的影响:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>水位标记可能设置的过短，因此在水位标记达到后仍然有记录到达。对于分布式的数据源头来说，很难去推断出一个完全完美的事件发生时间水位标记，因此无法完全依赖于水位标记，否则我们无法达到100%的准确性。</p>
</li>
<li>
<p>水位标记可能设置的过长。因为水位标记是全局性的进度指标，只要一个迟到的数据项就能影响到整个数据处理管道的水位标记。就算是一个正常工作的数据处理管道，它的处理延迟波动很小，受输入源的影响，这种延迟的基准仍然可能有几分钟甚至更高。因此，使用水位标记作为窗口完整信号并触发窗口计算结果很可能导致整个处理结果比Lambda架构有更高的延迟。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>由于上述的原因，我们认为光使用水位标记是不够的。从Lambda架构中我们获得了规避完整性问题的启发：它不是尽快地提供完全准确的答案，而是说，它先是尽快通过流式处理管道提供一个最佳的低延迟估计，同时承诺最终会通过批处理管道提供正确的和一致的答案(当然前提条件是批处理作业启动时，需要的数据应该已经全部到达了；如果数据后期发生了变化，那么批处理要重新执行以获得准确答案)。如果我们要在一个单一的数据处理管道里做到同样的事情(不管采用哪种执行引擎)，那么我们需要一种对任一窗口能够提供多种答案(或者可以叫做窗格, 译者注：对窗口这个比喻的引申)的方式。我们把这种功能叫做“触发器”。这种"触发器"可以选择在何时触发指定窗口的输出结果。</p>
</div>
<div class="paragraph">
<p>简单来说，触发器是一种受内部或者外信号激励的激发GroupByKeyAndWindow执行并输出执行结果的机制。他们对窗口模型是互补的，各自从不同的时间维度上影响系统的行为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>窗口 决定哪些事件发生时间段(where)的数据被分组到一起来进行聚合操作</p>
</li>
<li>
<p>触发 决定在什么处理时间(when)窗口的聚合结果被处理输出成一个窗格</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>我们的系统提供了基于窗口的完成度估计的预定义触发器。(完成度估计基于水位标记。完成度估计也包括水位标记完成百分位。它提供了一种有效的处理迟到记录的语义，而且在批处理和流处理引擎中都适用。允许使用者处理少量的一部分的记录来快速获得结果，而不是痴痴地等待最后的一点点数据到来)。触发器也有基于处理时间的，基于数据抵达状况的(如记录数，字节数，数据到达标记(punctuations)，模式匹配等)。我们也支持对基础触发器进行逻辑组合(与，或)，循环，序列和其他一些复合构造方法。另外，用户可以基于执行引擎的元素(如水位计时器，处理时间计时器，数据到达，复合构造)和任意的外部相关信号(如数据注入请求，外部数据进展指标，RPC完成回调等)自定义触发器。在2.4里我们会更详细地看一些具体的例子。</p>
</div>
<div class="paragraph">
<p>除了控制窗口结果计算何时触发，触发器还提供了三种不同的模式来控制不同的窗格(计算结果)之间是如何相互关联的。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>抛弃 窗口触发后，窗口内容被抛弃，而之后窗口计算的结果和之前的结果不存在相关性。当下游的数据消费者(不管是数据处理管道的内部还是外部)希望触发计算结果之间相互独立(比如对插入的数据进行求和的场景)，那么这种情况就比较适用。另外，抛弃因为不需要缓存历史数据，因此对比其他两种模式，抛弃模式在状态缓存上是最高效的。不过累积性的操作可以建模成Dataflow的Combiner，对窗口状态管理可以用增量的方式处理。对我们视频观看会话的用例来说，抛弃模式是不够的，因为要求下游消费者只关心会话的部分数据是不合理的。</p>
</li>
<li>
<p>累积：触发后，窗口内容被完整保留住持久化的状态中，而后期的计算结果成为对上一次结果的一个修正的版本。这种情况下，当下游的消费者收到同一个窗口的多次计算结果时，会用新的计算结果覆盖掉老的计算结果。这也是Lambda架构使用的方式，流处理管道产出低延迟的结果，之后被批处理管道的结果覆盖掉。对视频会话的用例来说，如果我们把会话窗口的内容进行计算然后把结果直接写入到支持更新的输出源(如数据库或者键值存储)，这种方案是足够的了。</p>
</li>
<li>
<p>累积和撤回：触发后，在进行累积语义的基础上，计算结果的一份复制也被保留到持久化状态中。当窗口将来再次触发时，上一次的结果值先下发做撤回处理，然后新的结果作为正常数据下发。如果数据处理管道有多个串行的GroupByKeyAndWindow操作时，撤回是必要的，因为同一个窗口的不同触发计算结果可能在下游会被分组到不同键中去。在这种情况下，除非我们通过一个撤回操作，撤回上一次聚合操作的结果，否则下游的第二次聚合操作会产生错误的结果。Dataflow的combiner操作是支持撤回的，只要调用uncombine方法就可以进行撤回。而对于视频会话用例来说，这种模型是非常理想的。比如说，如果我们在下游从会话创建一开始，我们就基于会话的某些属性进行汇总统计，例如检查不受欢迎的广告(比如说在很多会话中这个广告的被观察时长不长于5秒)。早期的计算结果随着输入的增加(比如说原来在野外观看视频的用户已经回来了并上传了他们的日志)可能变得无效。对于包含多个阶段的聚合操作的复杂数据处理管道，撤回方式帮助我们应对源头数据的变化，得到正确的数据处理结果。(简单的撤回实现只能支持确定性的计算，而非确定性计算的支持需要更复杂，代价也更高。我们已经看到这样的使用场景，比如说概率模型, 译者注：比如说基于布隆过滤器的UV统计)。</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/eventtime.png" alt="eventtime">
</div>
</div>
<div class="paragraph">
<p>很多例子都要考虑水位线，因此我们的图当中也包括了理想的水位线，也包括了实际的水位线。直的虚线代表了理想的水位线，即，事件发生时间和数据处理时间不存在任何延迟，所有的数据一产生就马上消费了。不过考虑到分布式系统的不确定性，这两个时间之间有偏差是非常普遍的。在图5中，实际的水位线(黑色弯曲虚线)很好的说明了这一点。另外注意由于实际的水位线是猜测获得的，因此有一个迟到比较明显的数据点落在了水位线的后面。</p>
</div>
<div class="paragraph">
<p>如果我们在传统的批处理系统中构建上述的对数据进行求和的数据处理管道，那么我们会等待所有的数据到达，然后聚合成一个批次(因为我们现在假设所有的数据拥有同样的键)，再进行求和，得到了结果51。如图6所示黑色的长方形是这个运算的示意图。长方形的区域代表求和运算涵盖的处理时间和参与运算的数据的事件发生时间区间。长方形的上沿代表计算发生，获得结果的管道处理时间点。因为传统的批处理系统不关心数据的事件发生时间，所有的数据被涵盖在一个大的全局性窗口中，因此包含了所有事件发生时间内的数据。而且因为管道的输出在收到所有数据后只计算一次，因此这个输出包含了所有处理时间的数据(译者注：处理时间是数据系统观察到数据的时间，而不是运算发生时的时间。)</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/batchexecution.png" alt="batchexecution">
</div>
</div>
<div class="paragraph">
<p>注意上图中包含了水位线。尽管在传统批处理系统中不存在水位线的概念，但是在语义上我们仍然可以引入它。批处理的水位线刚开始时一直停留不动。直到系统收到了所有数据并开始处理，水位线近似平行于事件发生时间轴开始平移，然后一直延伸到无穷远处。我们之所以讨论这一点，是因为如果让流处理引擎在收到所有数据之后启动来处理数据，那么水位线进展和传统批处理系统是一模一样的。(译者注：这提示我们其实水位线的概念可以同样适用于批处理)</p>
</div>
<div class="paragraph">
<p>现在假设我们要把上述的数据处理管道改造成能够接入无边界数据源的管道。在Dataflow模型中，默认的窗口触发方式是当水位线移过窗口时吐出窗口的执行结果。但如果对一个无边界数据源我们使用了全局性窗口，那么窗口就永远不会触发(译者注：因为窗口的大小在不停地扩大)。因此，我们要么用其他的触发器触发计算(而不是默认触发器)，或者按某种别的方式开窗，而不是一个唯一的全局性窗口。否则，我们永远不会获得计算结果输出。</p>
</div>
<div class="paragraph">
<p>我们先来尝试改变窗口触发方式，因为这会帮助我们产生概念上一致的输出(一个全局的包含所有时间的按键进行求和)，周期性地输出更新的结果。在这个例子中，我们使用了Window.trigger操作，按处理时间每分钟周期性重复触发窗口的计算。我们使用累积的方式对窗口结果进行修正(假设结果输出到一个数据库或者KV数据库，因而新的结果会持续地覆盖之前的计算结果)。这样，如图7所示，我们每分钟(处理时间)产生更新的全局求和结果。注意图中半透明的输出长方形是相互重叠的，这是因为累积窗格处理机制计算时包含了之前的窗口内容。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">trigger</span><span class="tok-o">(</span><span class="tok-n">Repeat</span><span class="tok-o">(</span><span class="tok-n">AtPeriod</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">,</span> <span class="tok-n">MINUTE</span><span class="tok-o">)))</span>
    <span class="tok-o">.</span><span class="tok-na">accumulating</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/globalwindows.png" alt="globalwindows">
</div>
</div>
<div class="paragraph">
<p>如果我们想要求出每分钟的和的增量，那么我们可以使用窗格的抛弃模式，如图8所示。注意这是很多流处理引擎的处理时间窗口的窗口计算模式。窗格不再相互重合，因此窗口的结果包含了相互独立的时间区域内的数据。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">trigger</span><span class="tok-o">(</span><span class="tok-n">Repeat</span><span class="tok-o">(</span><span class="tok-n">AtPeriod</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">,</span> <span class="tok-n">MINUTE</span><span class="tok-o">)))</span>
    <span class="tok-o">.</span><span class="tok-na">discarding</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/discarding.png" alt="discarding">
</div>
</div>
<div class="paragraph">
<p>另外一种更健壮的处理时间窗口的实现方式，是把数据摄入时的数据到达时间作为数据的事件发生时间，然后使用事件发生时间窗口。这样的另一个效果是系统对流入系统的数据的事件发生时间非常清楚，因而能够生成完美的水位线，不会存在迟到的数据。如果数据处理场景中不关心真正的事件发生时间，或者无法获得真正的事件发生时间，那么采用这种方式生成事件发生时间是一种非常低成本且有效的方式。</p>
</div>
<div class="paragraph">
<p>在我们讨论其他类型的窗口前，我们先来考虑下另外一种触发器。一种常见的窗口模式是基于记录数的窗口。我们可以通过改变触发器为每多少条记录到达触发一次的方式来实现基于记录数的窗口。图9是一个以两条记录为窗口大小的例子。输出是窗口内相邻的两条记录之和。更复杂的记录数窗口(比如说滑动记录数窗口)可以通过定制化的窗口触发器来支持。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">trigger</span><span class="tok-o">(</span><span class="tok-n">Repeat</span><span class="tok-o">(</span><span class="tok-n">AtCount</span><span class="tok-o">(</span><span class="tok-mi">2</span><span class="tok-o">)))</span>
    <span class="tok-o">.</span><span class="tok-na">discarding</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/atcount.png" alt="atcount">
</div>
</div>
<div class="paragraph">
<p>我们接下来考虑支持无边界数据源的其他选项，不再仅仅考虑全局窗口。一开始，我们来观察固定的2分钟窗口，累积窗格。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">into</span><span class="tok-o">(</span><span class="tok-n">FixedWindows</span><span class="tok-o">.</span><span class="tok-na">of</span><span class="tok-o">(</span><span class="tok-mi">2</span><span class="tok-o">,</span> <span class="tok-n">MINUTES</span><span class="tok-o">)</span>
    <span class="tok-o">.</span><span class="tok-na">accumulating</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>这里没有定义触发器，那么系统采用的是默认触发器。相当于</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">into</span><span class="tok-o">(</span><span class="tok-n">FixedWindows</span><span class="tok-o">.</span><span class="tok-na">of</span><span class="tok-o">(</span><span class="tok-mi">2</span><span class="tok-o">,</span> <span class="tok-n">MINUTES</span><span class="tok-o">))</span>
    <span class="tok-o">.</span><span class="tok-na">trigger</span><span class="tok-o">(</span><span class="tok-n">Repeat</span><span class="tok-o">(</span><span class="tok-n">AtWatermark</span><span class="tok-o">())))</span>
    <span class="tok-o">.</span><span class="tok-na">accumulating</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>水位线触发器是指当水位线越过窗口底线时窗口被触发。我们这里假设批处理和流处理系统都实现了水位线(详见3.1)。Repeat代表的含义是如何处理迟到的数据。在这里Repeat意味着当有迟于水位线的记录到达时，窗口都会立即触发再次进行计算，因为按定义，此时水位线早已经越过窗口底线了。</p>
</div>
<div class="paragraph">
<p>图10-12描述了上述窗口在三种不同的数据处理引擎上运行的情况。首先我们来观察下批处理引擎上这个数据处理管道如何执行的。受限于我们当前的实现，我们认为数据源现在是有边界的数据源，而传统的批处理引擎会等待所有的数据到来。之后，我们会根据数据的事件发生时间处理，在模拟的水位线到达后窗口计算触发吐出计算结果。整个过程如图10所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/fixedwindowsbatch.png" alt="fixedwindowsbatch">
</div>
</div>
<div class="paragraph">
<p>然后来考虑一下微批次引擎，每分钟做一次批次处理。系统会每分钟收集输入的数据进行处理，反复重复进行。每个批次开始后，水位线会从批次的开始时间迅速上升到批次的结束时间(技术上来看基本上是即刻完成的，取决于一分钟内积压的数据量和数据处理管道的吞吐能力)。这样每轮微批次完成后系统会达到一个新的水位线，窗口的内容每次都可能会不同(因为有迟到的数据加入进来)，输出结果也会被更新。这种方案很好的兼顾了低延迟和结果的最终准确性。如图11所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/fixedwindowsmicrobatch.png" alt="fixedwindowsmicrobatch">
</div>
</div>
<div class="paragraph">
<p>接下来考虑数据管道在流处理引擎上的执行情况，如图12所示。大多数窗口在水位线越过它们之后触发执行。注意值为9的那个数据点在水位线之后到达。不管什么原因(移动设备离线，网络故障分区等)，系统并没有意识到那一条数据并没有到达，仍然提升了水位线并触发了窗口计算。当值为9的那条记录到达后，窗口会重新触发，计算出一个新的结果值。</p>
</div>
<div class="paragraph">
<p>如果说我们一个窗口只有一个输出，而且针对迟到的数据仅做一次的修正，那么这个计算方式还是不错的。不过因为窗口要等待水位线进展，整体上的延迟比起微批次系统可能要更糟糕，这就是我们之前在2.3里所说的，单纯依赖水位线可能引起的问题(水位线可能太慢)</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/fixedwindowsstreaming.png" alt="fixedwindowsstreaming">
</div>
</div>
<div class="paragraph">
<p>如果我们想降低整体的延迟，那么我们可以提供按数据处理时间的触发器进行周期性的触发，这样我们能够尽早得到窗口的计算结果，并且在随后得到周期性的更新，直到水位线越过窗口边界。参见图13。这样我们能够得到比微批次系统更低的延迟，因为数据一到达就进入了窗口随后就可能被触发，而不像在微批次系统里必须等待一个批次数据完全到达。假设微批次系统和流处理系统都是强一致的，那么我们选择哪种引擎，就是在能接受的延迟程度和计算成本之间的选择(对微批次系统也是批大小的选择)。这就是我们这个模型想要达到的目标之一。参见图13：固定窗口，流处理，部分窗格</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">into</span><span class="tok-o">(</span><span class="tok-n">FixedWindows</span><span class="tok-o">.</span><span class="tok-na">of</span><span class="tok-o">(</span><span class="tok-mi">2</span><span class="tok-o">,</span> <span class="tok-n">MINUTES</span><span class="tok-o">))</span>
        <span class="tok-o">.</span><span class="tok-na">trigger</span><span class="tok-o">(</span><span class="tok-n">SequenceOf</span><span class="tok-o">(</span>
            <span class="tok-n">RepeatUntil</span><span class="tok-o">(</span>
                <span class="tok-n">AtPeriod</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">,</span> <span class="tok-n">MINUTE</span><span class="tok-o">),</span>
                <span class="tok-n">AtWatermark</span><span class="tok-o">()),</span>
            <span class="tok-n">Repeat</span><span class="tok-o">(</span><span class="tok-n">AtWatermark</span><span class="tok-o">())))</span>
        <span class="tok-o">.</span><span class="tok-na">accumulating</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/fixedwindowsstreamingpartial.png" alt="fixedwindowsstreamingpartial">
</div>
</div>
<div class="paragraph">
<p>作为最后一个例子，我们来看一下如何支持之前提到的视频会话需求(为了保持例子之间的一致性，我们继续把求和作为我们的计算内容。改变成其他的聚合函数也是很容易的)。我们把窗口定义为会话窗口，会话超时时间为1分钟，并且支持回撤操作。这个例子也体现了我们把模型的四个维度拆开之后带来的灵活的可组合性(计算什么，在哪段事件发生时间里计算，在哪段处理时间里真正触发计算，计算产生的结果后期如何进行修正)。也演示了对之前的计算结果可以进行撤回是一个非常强力的工具，否则可能会让下游之前接收到的数据无法得到修正。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="java"><span></span><span class="tok-n">PCollection</span><span class="tok-o">&lt;</span><span class="tok-n">KV</span><span class="tok-o">&lt;</span><span class="tok-n">String</span><span class="tok-o">,</span> <span class="tok-n">Integer</span><span class="tok-o">&gt;&gt;</span> <span class="tok-n">output</span> <span class="tok-o">=</span> <span class="tok-n">input</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Window</span><span class="tok-o">.</span><span class="tok-na">into</span><span class="tok-o">(</span><span class="tok-n">Sessions</span><span class="tok-o">.</span><span class="tok-na">withGapDuration</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">,</span> <span class="tok-n">MINUTE</span><span class="tok-o">))</span>
        <span class="tok-o">.</span><span class="tok-na">trigger</span><span class="tok-o">(</span><span class="tok-n">SequenceOf</span><span class="tok-o">(</span>
            <span class="tok-n">RepeatUntil</span><span class="tok-o">(</span>
                <span class="tok-n">AtPeriod</span><span class="tok-o">(</span><span class="tok-mi">1</span><span class="tok-o">,</span> <span class="tok-n">MINUTE</span><span class="tok-o">),</span>
                <span class="tok-n">AtWatermark</span><span class="tok-o">()),</span>
            <span class="tok-n">Repeat</span><span class="tok-o">(</span><span class="tok-n">AtWatermark</span><span class="tok-o">())))</span>
        <span class="tok-o">.</span><span class="tok-na">accumulatingAndRetracting</span><span class="tok-o">())</span>
    <span class="tok-o">.</span><span class="tok-na">apply</span><span class="tok-o">(</span><span class="tok-n">Sum</span><span class="tok-o">.</span><span class="tok-na">integersPerKey</span><span class="tok-o">());</span></code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/sessionsretract.png" alt="sessionsretract">
</div>
</div>
<div class="paragraph">
<p>在这个例子中，我们首先接收到了数据5和数据7。由于5和7之间事件发生时间大于1分钟，因此被当做了两个会话。在第一次窗口被触发时，产生了两条计算结果，和分别为5和7。在第二个因处理时间引起的窗口触发时，我们接收到了数据3,4,3，并且第一个3和上一个7之间时间大于1分钟，因此被分组到一个新的会话窗口，窗口触发计算并输出了计算结果10。紧接着，数据8到达了。数据8的到达使得数据7,3,4,3,8合并成了一个大窗口。当水位线越过数据点8后，新窗口计算被触发。触发后需要先撤回之前两个小窗口的计算结果，撤回方式是往下游发送两条键为之前的两个会话标记，值为-7和-10的记录，然后发送一个新的值为25的新窗口计算结果。同样，当值为9的记录迟于水位线到达后，之前的所有7条记录都合并成了一个会话，因此要对之前的会话再次进行撤回。值为-5和-25的记录又被发送往下游，新的值为39的会话记录随后也被发往下游。</p>
</div>
<div class="paragraph">
<p>同样的操作在处理最后3条值为3,8,1的记录时也会发生，先是输出了结果值3，随后回撤了这个计算结果，输出了合并会话后的结果值12。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_8_3_实现和设计">8.3 实现和设计</h3>
<div class="sect3">
<h4 id="_8_3_1_实现">8.3.1 实现</h4>
<div class="paragraph">
<p>我们已经用FlumeJava实现了这个模型，使用MillWheel作为底层的流执行引擎；在本文写作的时候，针对公有云服务Cloud Dataflow的重新实现也接近完成。由于这些系统要么是谷歌的内部系统，要么是共有云服务，因此为简洁起见，实现的细节我们略掉了。可以提及的让人感兴趣的一点是，核心的窗口机制代码，触发机制代码是非常通用的，绝大部分都同时适用于批处理引擎实现和流处理引擎实现。这个实现本身也值得在将来进行更进一步的分析。</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_2_设计原则">8.3.2 设计原则</h4>
<div class="paragraph">
<p>尽管我们很多的设计其实是受到3.3节所描述的真实业务场景启发，我们在设计中也遵从了一系列的核心原则。这些原则我们认为是这个模型必须要遵循的。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>永远不要依赖任何的数据完整性标记(译者注：如水位标记)</p>
</li>
<li>
<p>灵活性，要能覆盖已知的多样化的使用用例，并且覆盖将来可能的使用用例</p>
</li>
<li>
<p>对于每个预期中的执行引擎，(模型抽象)不但要正确合理，而且要有额外的附加价值</p>
</li>
<li>
<p>鼓励实现的透明性</p>
</li>
<li>
<p>支持对数据在它们产生的上下文中进行健壮的分析。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>可以这么说，下述的使用案例决定了模型的具体功能，而这些设计原则决定了模型整体的特征和框架。我们认为这两者是我们设计的模型具有完全性，普遍性的根本原因。</p>
</div>
</div>
<div class="sect3">
<h4 id="_8_3_3_业务场景">8.3.3 业务场景</h4>
<div class="paragraph">
<p>在我们设计Dataflow模型的过程中，我们考虑了FlumeJava和MillWheel系统在这些年遇到的各种真实场景。那些良好工作的设计，我们保留到了模型中，而那些工作不那么良好的设计激励我们采用新的方法重新设计。下面我们简单介绍一些影响过我们设计的场景。</p>
</div>
<div class="sect4">
<h5 id="_8_3_3_1_大规模数据回写和lambda架构统一模型">8.3.3.1 大规模数据回写和Lambda架构；统一模型</h5>
<div class="paragraph">
<p>有一些团队在MillWheel上跑日志链接作业。这其中有一个特别大的日志链接处理作业在MillWheel上按流模式运行，而另外一个单独的FlumeJava批处理作业用来对流处理作业的结果进行大规模的回写。一个更好的设计是使用一个统一的模型，对数据处理逻辑只实现一次，但是能够在流处理引擎和批处理引擎不经修改而同时运行。这是第一个激发我们思考去针对批处理，微批次处理和流处理建立一个统一模型的业务场景。这也是图10-12所展示的。</p>
</div>
<div class="paragraph">
<p>另外一个激发我们设计统一模型的场景是Lambda架构的使用。尽管谷歌大多数数据处理的场景是由批处理系统和流处理系统分别单独承担的，不过有一个MillWheel的内部客户在弱一致性的模式下运行他们的流处理作业，用一个夜间的MR作业来生产正确的结果。他们发现他们的客户不信任弱一致性的实时结果，被迫重新实现了一个系统来支持强一致性，这样他们就能提供可靠的，低延时的数据处理结果。这个场景进一步激励我们能支持灵活地选择不同的执行引擎。</p>
</div>
</div>
<div class="sect4">
<h5 id="_8_3_3_2_非对齐窗口会话">8.3.3.2 非对齐窗口：会话</h5>
<div class="paragraph">
<p>从一开始我们就知道我们需要支持会话；事实上这是我们窗口模型对现有模型而言一个重大的贡献。会话对谷歌来说是一个非常重要的使用场景(也是MillWheel创建的原因之一)。会话窗口在一系列的产品域中都有应用，如搜索，广告，分析，社交和YouTube。基本上任何关心把用户的分散活动记录进行相互关联分析都需要通过会话来进行处理。因此，支持会话成为我们设计中的最重要考虑。如图14所示，支持会话在Dataflow中是非常简单的。</p>
</div>
</div>
<div class="sect4">
<h5 id="_8_3_3_3_支付触发器累加和撤回">8.3.3.3 支付：触发器，累加和撤回</h5>
<div class="paragraph">
<p>有两个在MillWheel上跑支付作业的团队遇到的问题对模型的一部分也有启发作用。当时我们的设计实践是使用水位线作为数据完全到达的指标。然后写额外的逻辑代码来处理迟到的数据或者更改源头数据。由于缺乏一个支持更新和撤回的系统，负责资源利用率方案的团队最终放弃了我们的平台，构建了自己独立的解决方案(他们最后使用的模型和我们同时设计开发的模型事实上非常类似)。另一个支付团队的数据源头有少部分缓慢到达的数据，造成了水位线延迟，这给他们带来了大问题。这些系统上的缺陷成为我们对现有系统需要进行改良设计的重要动因，并且把我们的考虑点从保证数据的完整性转移到了对迟到数据的可适应性。对于这个场景的思考总结带来了两个方面：一个方面是能够精确，灵活地确定何时将窗口内容物化的触发器(如图7～图14所示)，对同样的输入数据集也可以使用多种多样地结果输出模式进行处理。另外一方面是通过累积和撤回能够支持增量处理。(图14)</p>
</div>
</div>
<div class="sect4">
<h5 id="_8_3_3_4_统计计算水位线触发器">8.3.3.4 统计计算：水位线触发器</h5>
<div class="paragraph">
<p>很多MillWheel作业用来进行汇总统计(如平均延迟)。对这些作业来说，100%的准确性不是必须的，但是在合理的时间范围内得到一个接近完整的统计是必须的。考虑到对于结构化的输入(如日志文件)，使用水位线就能达到很高程度的准确度。这些客户发现使用单次的的基于水位线的触发器就可以获得高度准确的统计。水位线触发器如图12所示。</p>
</div>
<div class="paragraph">
<p>我们有一些滥用检测的作业运行在MillWheel中。滥用检测是另外一种快速处理大部分数据比缓慢处理掉所有数据要远远更有价值的场景。因此，他们会大量地使用水位线百分位触发器。这个场景促使我们在模型中加入了对水位线百分位触发器的支持。</p>
</div>
<div class="paragraph">
<p>与此相关的，批处理作业中的一个痛点是部分处理节点的缓慢进度会成为执行时间中的长尾，拖慢整个进度。除了可以通过动态平衡作业来缓解这个问题，FlumeJava也支持基于整体完成百分度来选择是否终止长尾节点。用统一模型来描述批处理中遇到的这个场景的时候，水位线百分位触发器可以很自然地进行表达，不需要在引入额外的定制功能、定制接口。</p>
</div>
</div>
<div class="sect4">
<h5 id="_8_3_3_5_推荐处理时间触发器">8.3.3.5 推荐：处理时间触发器</h5>
<div class="paragraph">
<p>另外一种我们考虑过的场景是从大量的谷歌数据资产中构建用户活动树(本质上是会话树)。这些树用来根据用户的兴趣来做推荐。在这些作业中我们使用处理时间作为触发器。这是因为，对于用户推荐来说，周期性更新的，即便是基于不完备数据的用户活动树比起持续等待水位线越过会话窗口边界(即会话结束)获得完全的数据要有意义的多。这也意味着由于部分少量数据引起的水位线进展延迟不影响基于其他已经到达的数据进行计算并获得有效的用户活动树。考虑到这种场景，我们包含了基于处理时间的触发器(如图7和图8所示)</p>
</div>
</div>
<div class="sect4">
<h5 id="_8_3_3_6_异常探测数据驱动和组合触发器">8.3.3.6 异常探测：数据驱动和组合触发器</h5>
<div class="paragraph">
<p>在MillWheel的论文中，我们描述了一种用来检测谷歌网站搜索查询趋势的微分异常探测数据处理管道。当我们为模型设计触发器的时候，这种微分异常探测系统启发我们设计了数据驱动触发器。这种微分探测器检测网站检索流，通过统计学估计来计算搜索查询请求量是否存在一个毛刺。如果系统认为一个毛刺即将产生，系统将发出一个启动型号。当他们认为毛刺已经消除，那么他们会发出一个停止信号(译者注：可能会对接系统自动对系统扩容或缩容)。尽管我们可以采用别的方式来触发计算，比如说Trill的标点符(Punctuations)，但是对于异常探测你可能希望一旦系统确认有异常即将发生，系统应该立即输出这个判断。标点符的使用事实上把流处理系统转换成了微批次处理系统，引入了额外的延迟。在调查过一些用户场景后，我们认为标点符不完全适合我们。因此我们在模型中引入了可定制化数据驱动触发器。同时这个场景也驱使我们支持触发器组合，因为在现实场景中，一个系统可能在处理多种微分计算，需要根据定义的一组逻辑来支持多种多样的输出。图9中的AtCount触发器是数据驱动触发器的例子，而图10-14使用了组合触发器。</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_8_4_总结">8.4 总结</h3>
<div class="paragraph">
<p>数据处理的未来是无边界数据处理。 尽管有边界数据的处理永远都有着重要地位并且有用武之地，但是语义上它会被无边界数据处理模型所涵盖。一方面，无边界数据处理技术发展上步履蹒跚，另一方面对于数据进行处理并消费的要求在不断提高，比如说，需要对按事件发生时间对数据处理，或者支持非对齐窗口等。要发展能够支撑未来业务需要的数据处理系统，当前存在的系统和模型是一个非常好的基础，但我们坚持相信如果要完善地解决用户对无边界数据处理的需求，我们必须根本地改变我们的思维。</p>
</div>
<div class="paragraph">
<p>根据我们多年在谷歌处理大规模无边界数据的实践经验，我们相信我们提出的模型一个非常好的进展。它支持非对齐，事件发生时间窗口。这些都是当前用户所需要的。它提供了灵活的窗口触发机制，支持窗口累积和撤回，把关注点从寻求等待数据的完整性变为自动适应现实世界中持续变更的数据源。它对批处理，微批次，流处理提供了统一的抽象，允许数据开发人员灵活从三者中选择。同时，它避免了单一系统容易把系统本身的构建蔓延到数据处理抽象层面中去的问题。它的灵活性让数据开发者能根据使用场景恰当地平衡数据处理的准确性，成本和延迟程度。对于处理多样化的场景和需求来说，这一点很关键。最后，通过把数据处理的逻辑划分为计算什么，在哪个事件发生时间范围内计算，在什么处理时间点触发计算，如何用新的结果订正之前的数据处理结果让整个数据处理逻辑透明清晰。我们希望其他人能够认同这个模型并且和我们一起推进这个复杂而又令人着迷的领域的发展。</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2019-06-05 15:40:40 +0800
</div>
</div>
<style>
pre.pygments .hll { background-color: #ffffcc }
pre.pygments  { background: #f8f8f8; }
pre.pygments .tok-c { color: #408080; font-style: italic } /* Comment */
pre.pygments .tok-err { border: 1px solid #FF0000 } /* Error */
pre.pygments .tok-k { color: #008000; font-weight: bold } /* Keyword */
pre.pygments .tok-o { color: #666666 } /* Operator */
pre.pygments .tok-ch { color: #408080; font-style: italic } /* Comment.Hashbang */
pre.pygments .tok-cm { color: #408080; font-style: italic } /* Comment.Multiline */
pre.pygments .tok-cp { color: #BC7A00 } /* Comment.Preproc */
pre.pygments .tok-cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
pre.pygments .tok-c1 { color: #408080; font-style: italic } /* Comment.Single */
pre.pygments .tok-cs { color: #408080; font-style: italic } /* Comment.Special */
pre.pygments .tok-gd { color: #A00000 } /* Generic.Deleted */
pre.pygments .tok-ge { font-style: italic } /* Generic.Emph */
pre.pygments .tok-gr { color: #FF0000 } /* Generic.Error */
pre.pygments .tok-gh { color: #000080; font-weight: bold } /* Generic.Heading */
pre.pygments .tok-gi { color: #00A000 } /* Generic.Inserted */
pre.pygments .tok-go { color: #888888 } /* Generic.Output */
pre.pygments .tok-gp { color: #000080; font-weight: bold } /* Generic.Prompt */
pre.pygments .tok-gs { font-weight: bold } /* Generic.Strong */
pre.pygments .tok-gu { color: #800080; font-weight: bold } /* Generic.Subheading */
pre.pygments .tok-gt { color: #0044DD } /* Generic.Traceback */
pre.pygments .tok-kc { color: #008000; font-weight: bold } /* Keyword.Constant */
pre.pygments .tok-kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
pre.pygments .tok-kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
pre.pygments .tok-kp { color: #008000 } /* Keyword.Pseudo */
pre.pygments .tok-kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
pre.pygments .tok-kt { color: #B00040 } /* Keyword.Type */
pre.pygments .tok-m { color: #666666 } /* Literal.Number */
pre.pygments .tok-s { color: #BA2121 } /* Literal.String */
pre.pygments .tok-na { color: #7D9029 } /* Name.Attribute */
pre.pygments .tok-nb { color: #008000 } /* Name.Builtin */
pre.pygments .tok-nc { color: #0000FF; font-weight: bold } /* Name.Class */
pre.pygments .tok-no { color: #880000 } /* Name.Constant */
pre.pygments .tok-nd { color: #AA22FF } /* Name.Decorator */
pre.pygments .tok-ni { color: #999999; font-weight: bold } /* Name.Entity */
pre.pygments .tok-ne { color: #D2413A; font-weight: bold } /* Name.Exception */
pre.pygments .tok-nf { color: #0000FF } /* Name.Function */
pre.pygments .tok-nl { color: #A0A000 } /* Name.Label */
pre.pygments .tok-nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
pre.pygments .tok-nt { color: #008000; font-weight: bold } /* Name.Tag */
pre.pygments .tok-nv { color: #19177C } /* Name.Variable */
pre.pygments .tok-ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
pre.pygments .tok-w { color: #bbbbbb } /* Text.Whitespace */
pre.pygments .tok-mb { color: #666666 } /* Literal.Number.Bin */
pre.pygments .tok-mf { color: #666666 } /* Literal.Number.Float */
pre.pygments .tok-mh { color: #666666 } /* Literal.Number.Hex */
pre.pygments .tok-mi { color: #666666 } /* Literal.Number.Integer */
pre.pygments .tok-mo { color: #666666 } /* Literal.Number.Oct */
pre.pygments .tok-sa { color: #BA2121 } /* Literal.String.Affix */
pre.pygments .tok-sb { color: #BA2121 } /* Literal.String.Backtick */
pre.pygments .tok-sc { color: #BA2121 } /* Literal.String.Char */
pre.pygments .tok-dl { color: #BA2121 } /* Literal.String.Delimiter */
pre.pygments .tok-sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
pre.pygments .tok-s2 { color: #BA2121 } /* Literal.String.Double */
pre.pygments .tok-se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
pre.pygments .tok-sh { color: #BA2121 } /* Literal.String.Heredoc */
pre.pygments .tok-si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
pre.pygments .tok-sx { color: #008000 } /* Literal.String.Other */
pre.pygments .tok-sr { color: #BB6688 } /* Literal.String.Regex */
pre.pygments .tok-s1 { color: #BA2121 } /* Literal.String.Single */
pre.pygments .tok-ss { color: #19177C } /* Literal.String.Symbol */
pre.pygments .tok-bp { color: #008000 } /* Name.Builtin.Pseudo */
pre.pygments .tok-fm { color: #0000FF } /* Name.Function.Magic */
pre.pygments .tok-vc { color: #19177C } /* Name.Variable.Class */
pre.pygments .tok-vg { color: #19177C } /* Name.Variable.Global */
pre.pygments .tok-vi { color: #19177C } /* Name.Variable.Instance */
pre.pygments .tok-vm { color: #19177C } /* Name.Variable.Magic */
pre.pygments .tok-il { color: #666666 } /* Literal.Number.Integer.Long */
</style>
</body>
</html>