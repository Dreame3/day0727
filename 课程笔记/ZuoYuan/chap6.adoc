== 第六章 Event Time与Window

=== 6.1 Event Time的引入

在Flink的流式处理中，绝大部分的业务都会使用Event Time，一般只在Event Time无法使用时，才会被迫使用Processing Time或者Ingestion Time。
如果要使用Event Time，那么需要引入Event Time的时间属性，引入方式如下所示：

[source,scala]
----
val env = StreamExecutionEnvironment.getExecutionEnvironment
 
// 从调用时刻开始给env创建的每一个stream追加时间特征
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
----

=== 6.2 Watermark

==== 6.2.1 基本概念

我们知道，流处理从事件产生，到流经source，再到operator，中间是有一个过程和时间的，虽然大部分情况下，流到operator的数据都是按照事件产生的时间顺序来的，但是也不排除由于网络、分布式等原因，导致乱序的产生，所谓乱序，就是指Flink接收到的事件的先后顺序不是严格按照事件的Event Time顺序排列的。

image::stream_watermark_in_order.svg[]

image::stream_watermark_out_of_order.svg[]

那么此时出现一个问题，一旦出现乱序，如果只根据Event Time决定Window的运行，我们不能明确数据是否全部到位，但又不能无限期的等下去，此时必须要有个机制来保证一个特定的时间后，必须触发Window去进行计算了，这个特别的机制，就是Watermark。

* Watermark是一种衡量Event Time进展的机制，它是数据本身的一个隐藏属性，数据本身携带着对应的Watermark。
* Watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用Watermark机制结合Window来实现。
* 数据流中的Watermark用于表示timestamp小于Watermark的数据，都已经到达了，因此，Window的执行也是由Watermark触发的。
* Watermark可以理解成一个延迟触发机制，我们可以设置Watermark的延时时长t，每次系统会校验已经到达的数据中最大的maxEventTime，然后认定Event Time小于maxEventTime - t的所有数据都已经到达，如果有窗口的停止时间等于maxEventTime – t，那么这个窗口被触发执行。

有序流的Watermarker如下图所示：(Watermark的延时时长设置为0)

image::inorderdata.png[]

乱序流的Watermarker如下图所示：(Watermark的延时时长设置为2)

image::outorderdata.png[]

当Flink接收到每一条数据时，都会产生一条Watermark，这条Watermark就等于当前所有到达数据中的``maxEventTime - 延迟时长``，也就是说，Watermark是由数据携带的，一旦数据携带的Watermark比当前未触发的窗口的停止时间要晚，那么就会触发相应窗口的执行。由于Watermark是由数据携带的，因此，如果运行过程中无法获取新的数据，那么没有被触发的窗口将永远都不被触发。

上图中，我们设置的允许最大延迟到达时间为2s，所以时间戳为7s的事件对应的Watermark是5s，时间戳为12s的事件的Watermark是10s，如果我们的窗口1是1s～5s，窗口2是6s～10s，那么时间戳为7s的事件到达时的Watermarker恰好触发窗口1，时间戳为12s的事件到达时的Watermark恰好触发窗口2。
 
Watermark就是触发前一窗口的"关窗时间"，一旦触发关门那么以当前时刻为准在窗口范围内的所有数据都会收入窗中。

只要没有达到水位那么不管现实中的时间推进了多久都不会触发关窗。

==== 6.2.2 Watermark的引入

Event Time的使用一定要**指定数据源中的时间戳**。否则程序无法知道事件的事件时间是什么(数据源里的数据没有时间戳的话，就只能使用Processing Time了)。

Flink暴露了``TimestampAssigner``接口供我们实现，使我们可以自定义如何从事件数据中抽取时间戳。

[source,scala]
----
val env = StreamExecutionEnvironment.getExecutionEnvironment
 
// 从调用时刻开始给env创建的每一个stream追加时间特征
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)

val readings: DataStream[SensorReading] = env
  .addSource(new SensorSource)
  .assignTimestampsAndWatermarks(new MyAssigner())
----

MyAssigner有两种类型

* AssignerWithPeriodicWatermarks
* AssignerWithPunctuatedWatermarks

以上两个接口都继承自TimestampAssigner。

*Assigner with periodic watermarks*

周期性的生成水印：系统会周期性的将水印插入到流中(水印也是一种特殊的事件！)。默认周期是200毫秒。可以使用ExecutionConfig.setAutoWatermarkInterval()方法进行设置。

[source,scala]
----
val env = StreamExecutionEnvironment.getExecutionEnvironment
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
// 每隔5秒产生一个水印
env.getConfig.setAutoWatermarkInterval(5000)
----

产生水印的逻辑：每隔5秒钟，Flink会调用AssignerWithPeriodicWatermarks的getCurrentWatermark()方法。如果方法返回一个时间戳大于之前水印的时间戳，新的水印会被插入到流中。这个检查保证了水印是单调递增的。如果方法返回的时间戳小于等于之前水印的时间戳，则不会产生新的水印。

例子，自定义一个周期性的时间戳抽取

[source,scala]
----
class PeriodicAssigner extends AssignerWithPeriodicWatermarks[SensorReading] {
  val bound: Long = 60 * 1000 // 延时为1分钟
  val maxTs: Long = Long.MinValue // 观察到的最大时间戳

  override def getCurrentWatermark: Watermark = {
    new Watermark(maxTs - bound)
  }

  override def extractTimestamp(r: SensorReading, previousTS: Long) = {
    maxTs = maxTs.max(r.timestamp)
    r.timestamp
  }
}
----

相当于实现了``BoundedOutOfOrdernessTimestampExtractor[SensorReading](Time.milliseconds(1000))``

如果我们事先得知数据流的时间戳是单调递增的，也就是说没有乱序。我们可以使用``assignAscendingTimestamps``，方法会直接使用数据的时间戳生成水印。

[source,scala]
----
val stream: DataStream[SensorReading] = ...
val withTimestampsAndWatermarks = stream
  .assignAscendingTimestamps(e => e.timestamp)
----

----
E(1), W(1), E(2), W(2), ...
----

如果我们能大致估算出数据流中的事件的最大延迟时间，可以使用如下代码

[source,scala]
----
val stream: DataStream[SensorReading] = ...
val withTimestampsAndWatermarks = stream.assignTimestampsAndWatermarks(
  new BoundedOutOfOrdernessTimestampExtractor[SensorReading](
    Time.seconds(10))(e => e.timestamp))
----

----
E(10), W(0), E(8), E(7), E(11), W(1), ...
----

*Assigner with punctuated watermarks*

直接上代码，只给sensor_1的传感器的数据流插入水印

[source,scala]
----
class PunctuatedAssigner extends AssignerWithPunctuatedWatermarks[SensorReading] {
  val bound: Long = 60 * 1000

  override def checkAndGetNextWatermark(r: SensorReading, extractedTS: Long): Watermark = {
    if (r.id == "sensor_1") {
      new Watermark(extractedTS - bound)
    } else {
      null
    }
  }

  override def extractTimestamp(r: SensorReading, previousTS: Long): Long = {
    r.timestamp
  }
}
----

在Flink中，水印由应用程序开发人员生成，这通常需要对相应的领域有一定的了解。完美的水印永远不会错：时间戳小于水印标记时间的事件不会再出现。在特殊情况下(例如非乱序事件流)，最近一次事件的时间戳就可能是完美的水印。启发式水印则相反，它只估计时间，因此有可能出错，即迟到的事件(其时间戳小于水印标记时间)晚于水印出现。针对启发式水印，Flink提供了处理迟到元素的机制。

设定水印通常需要用到领域知识。举例来说，如果知道事件的迟到时间不会超过5秒，就可以将水印标记时间设为收到的最大时间戳减去5秒。另一种做法是，采用一个Flink作业监控事件流，学习事件的迟到规律，并以此构建水印生成模型。

如果水印迟到得太久，收到结果的速度可能就会很慢，解决办法是在水印到达之前输出近似结果(Flink可以实现)。如果水印到达得太早，则可能收到错误结果，不过Flink处理迟到数据的机制可以解决这个问题。上述问题看起来很复杂，但是恰恰符合现实世界的规律——大部分真实的事件流都是乱序的，并且通常无法了解它们的乱序程度(因为理论上不能预见未来)。水印是唯一让我们直面乱序事件流并保证正确性的机制; 否则只能选择忽视事实，假装错误的结果是正确的。


=== 6.3 EvnetTimeWindow API

==== 6.3.1 滚动窗口(TumblingEventTimeWindows) 

[source,scala]
----
def main(args: Array[String]): Unit = {
    // 环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val dstream: DataStream[String] = env.socketTextStream("localhost", 9999)

    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream
      .map { text =>
        val arr: Array[String] = text.split(" ")
        (arr(0), arr(1).toLong, 1)
      }

    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream
      .assignTimestampsAndWatermarks(
        new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
          override def extractTimestamp(element: (String, Long, Int)): Long = {
            return element._2
          }
        })

    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream
      .keyBy(0)

    textKeyStream.print("textkey:")

    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream
      .window(TumblingEventTimeWindows.of(Time.seconds(2)))

    val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream
      .fold(new mutable.HashSet[Long]()) { case (set, (key, ts, count)) =>
        set += ts
      }

    groupDstream.print("window::::").setParallelism(1)

    env.execute()
  }
----

结果是按照Event Time的时间窗口计算得出的，而无关系统的时间(包括输入的快慢)。

==== 6.3.2 滑动窗口(SlidingEventTimeWindows)

[source,scala]
----
def main(args: Array[String]): Unit = {
  //  环境
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
  env.setParallelism(1)

  val dstream: DataStream[String] = env.socketTextStream("localhost", 9999)

  val textWithTsDstream: DataStream[(String, Long, Int)] = dstream
    .map { text =>
      val arr: Array[String] = text.split(" ")
      (arr(0), arr(1).toLong, 1)
    }

  val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream
    .assignTimestampsAndWatermarks(
      new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
        override def extractTimestamp(element: (String, Long, Int)): Long = {
          return element._2
        }
      })

  val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream
    .keyBy(0)
  
  textKeyStream.print("textkey:")

  val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream
    .window(SlidingEventTimeWindows.of(Time.seconds(2), Time.milliseconds(500)))

  val groupDstream: DataStream[mutable.HashSet[Long]] = windowStream
    .fold(new mutable.HashSet[Long]()) { case (set, (key, ts, count)) =>
      set += ts
    }

  groupDstream.print("window::::").setParallelism(1)

  env.execute()
}
----

==== 6.3.3 会话窗口（EventTimeSessionWindows）

相邻两次数据的Event Time的时间差超过指定的时间间隔就会触发执行。如果加入Watermark，会在符合窗口触发的情况下进行延迟。到达延迟水位再进行窗口触发。

[source,scala]
----
def main(args: Array[String]): Unit = {
    //  环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val dstream: DataStream[String] = env.socketTextStream("localhost", 9999)

    val textWithTsDstream: DataStream[(String, Long, Int)] = dstream
      .map { text =>
        val arr: Array[String] = text.split(" ")
        (arr(0), arr(1).toLong, 1)
      }

    val textWithEventTimeDstream: DataStream[(String, Long, Int)] = textWithTsDstream
      .assignTimestampsAndWatermarks(
        new BoundedOutOfOrdernessTimestampExtractor[(String, Long, Int)](Time.milliseconds(1000)) {
          override def extractTimestamp(element: (String, Long, Int)): Long = {
            return element._2
          }
        })

    val textKeyStream: KeyedStream[(String, Long, Int), Tuple] = textWithEventTimeDstream
      .keyBy(0)

    textKeyStream.print("textkey:")

    val windowStream: WindowedStream[(String, Long, Int), Tuple, TimeWindow] = textKeyStream
      .window(EventTimeSessionWindows.withGap(Time.milliseconds(500)))

    windowStream
      .reduce((text1,text2) =>
        (text1._1, 0L, text1._3 + text2._3)
      )
      .map(_._3)
      .print("windows:::")
      .setParallelism(1)

    env.execute()
  }
----
